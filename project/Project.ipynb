{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "path_to_file = \"../data/Component_Faults_Data.csv\"\n",
    "df = pd.read_csv(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "x = df.iloc[:, :48].values\n",
    "y = df[\"class\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newer Solution for testing NN-Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports for class\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt    \n",
    "import itertools\n",
    "        \n",
    "\n",
    "\"\"\" \n",
    "    The following class helps in streamlining the building, training, and testing of a Neural Network (NN)\n",
    "    With it, we can see the effect on the result for changing a single parameter \n",
    "    So we only have to provide the name of the parameter we have to change, and the values we want to test it with\n",
    "\"\"\"\n",
    "class NeuralNetworkParameterTester:\n",
    "\n",
    "    # The config holds all the changeable parameters for building, training and testing the NN\n",
    "    parameter_config = {\n",
    "                'number_of_hidden_layers': [1],\n",
    "                'number_of_units_per_hidden_layer': [10],\n",
    "                'epochs': [100],\n",
    "                'batch_size': [64],\n",
    "                'activation_function': ['relu'],\n",
    "                'loss_function': ['categorical_crossentropy'],\n",
    "                'optimizer': ['sgd']}\n",
    "    \n",
    "    # Result of the test\n",
    "    result = []\n",
    "    \n",
    "    \"\"\" \n",
    "        If you want to test your parameters, then you have to call this class\n",
    "    \"\"\"       \n",
    "    def run(self):\n",
    "        \n",
    "        # Reset result\n",
    "        self.result = []\n",
    "        \n",
    "        # Build all possible parameter combinations and  ...\n",
    "        for config in self.__get_all_config_combinations():\n",
    "            # ... build the NN-model for it\n",
    "            model = self.__build(config)\n",
    "            # ... train the NN-model \n",
    "            trained_model, history = self.__train(config, model)\n",
    "            # ... test the NN-model and get the accuracy score\n",
    "            accuracy = self.__test(trained_model)\n",
    "\n",
    "            # Save the result\n",
    "            self.result.append({'parameter_config': config.copy(), \n",
    "                                \"result\": {'model': trained_model, \n",
    "                                           'accuracy': accuracy}})\n",
    "            \n",
    "    \"\"\" \n",
    "        The following method builds all combinations of your parameter-config\n",
    "    \"\"\"          \n",
    "    def __get_all_config_combinations(self):\n",
    "\n",
    "        raw_combinations = list(itertools.product(*(self.parameter_config[parameter] for parameter in self.parameter_config)))\n",
    "\n",
    "        config_combinations_list = []\n",
    "        for combination in raw_combinations:\n",
    "            c = {\n",
    "                'number_of_hidden_layers': combination[0],\n",
    "                'number_of_units_per_hidden_layer': combination[1],\n",
    "                'epochs': combination[2],\n",
    "                'batch_size': combination[3],\n",
    "                'activation_function': combination[4],\n",
    "                'loss_function': combination[5],\n",
    "                'optimizer': combination[6]}\n",
    "            \n",
    "            config_combinations_list.append(c)\n",
    "        \n",
    "        return config_combinations_list\n",
    "    \n",
    "    \"\"\" \n",
    "        The following method builds the NN-Model\n",
    "    \"\"\"   \n",
    "    def __build(self, config):\n",
    "\n",
    "        # Sequential model (Basic NN)\n",
    "        model = Sequential()        \n",
    "        # Building of input layer\n",
    "        model.add(Dense(config['number_of_units_per_hidden_layer'], \n",
    "                        input_dim=48, \n",
    "                        activation=config['activation_function']))\n",
    "        # Building of hidden layer(s)\n",
    "        for i in range(config['number_of_hidden_layers']):\n",
    "            model.add(Dense(config['number_of_units_per_hidden_layer'], \n",
    "                            activation=config['activation_function']))\n",
    "        # Building of output layer\n",
    "        model.add(Dense(11, activation=\"softmax\"))\n",
    "        # ?\n",
    "        model.compile(loss=config['loss_function'], \n",
    "                      optimizer=config['optimizer'], \n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    \"\"\" \n",
    "        The following method trains the NN-Model\n",
    "    \"\"\"   \n",
    "    def __train(self, config, model):\n",
    "        # xtrain and ytrain is the data from preprocessing\n",
    "        history = model.fit(x_train, \n",
    "                            y_train, \n",
    "                            epochs=config['epochs'], \n",
    "                            batch_size=config['batch_size'])  \n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    \"\"\" \n",
    "        The following method tests the NN-Model\n",
    "    \"\"\" \n",
    "    # TODO: look at this method more closely. So far just copy paste\n",
    "    @staticmethod\n",
    "    def __test(model):\n",
    "        y_pred = model.predict(x_test)\n",
    "        # Converting predictions to label\n",
    "        pred = list()\n",
    "        for i in range(len(y_pred)):\n",
    "            pred.append(np.argmax(y_pred[i]))\n",
    "        # Converting one hot encoded test label to label\n",
    "        test = list()\n",
    "        for i in range(len(y_test)):\n",
    "            test.append(np.argmax(y_test[i]))\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score(pred, test)\n",
    "        # TODO: calculate confusion matrix and put it in result\n",
    "        return accuracy\n",
    "                                    \n",
    "                                    \n",
    "    #--------------- Setter methods for setting parameters --------------------------------------#\n",
    "    \n",
    "    def set_number_of_hidden_layers(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"number_of_hidden_layers\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"number_of_hidden_layers\"] = [val]\n",
    "        \n",
    "    def set_number_of_units_per_hidden_layer(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"number_of_units_per_hidden_layer\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"number_of_units_per_hidden_layer\"] = [val]\n",
    "        \n",
    "    def set_activation_function(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"activation_function\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"activation_function\"] = [val]\n",
    "        \n",
    "    def set_epochs(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"epochs\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"epochs\"] = [val]\n",
    "        \n",
    "    def set_batch_size(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"batch_size\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"batch_size\"] = [val]\n",
    "        \n",
    "    def set_loss_function(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"loss_function\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"loss_function\"] = [val]\n",
    "        \n",
    "    def set_optimizer(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"optimizer\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"optimizer\"] = [val]\n",
    "        \n",
    "    #--------------- Resets the config to default values --------------------------------------#\n",
    "    \n",
    "    def reset_config(self):\n",
    "        parameter_config = {\n",
    "            'number_of_hidden_layers': [1],\n",
    "            'number_of_units_per_hidden_layer': [10],\n",
    "            'epochs': [100],\n",
    "            'batch_size': [64],\n",
    "            'activation_function': ['relu'],\n",
    "            'loss_function': ['categorical_crossentropy'],\n",
    "            'optimizer': ['sgd']}\n",
    "        \n",
    "        self.parameter_config = parameter_config\n",
    "        \n",
    "        \n",
    "    #--------------- Helper methods -----------------------------------------------------------#\n",
    "        \n",
    "    def __get_number_of_params_with_multiple_vals(self):\n",
    "        number_of_params_with_multiple_vals = 0 \n",
    "        for key in self.parameter_config.keys():\n",
    "            if len(self.parameter_config[key]) > 1:\n",
    "                number_of_params_with_multiple_vals += 1\n",
    "        return number_of_params_with_multiple_vals\n",
    "    \n",
    "    def __get_param_names_with_multiple_vals(self):\n",
    "        param_names_with_multiple_vals = [] \n",
    "        for key in self.parameter_config.keys():\n",
    "            if len(self.parameter_config[key]) > 1:\n",
    "                param_names_with_multiple_vals.append(key)\n",
    "        return param_names_with_multiple_vals\n",
    "        \n",
    "        \n",
    "    #--------------- Plotter methods -----------------------------------------------------------#\n",
    "    \n",
    "    def plot_result(self):\n",
    "        \n",
    "        number_of_params_with_multiple_vals = self.__get_number_of_params_with_multiple_vals()\n",
    "        param_names_with_multiple_vals = self.__get_param_names_with_multiple_vals()\n",
    "        \n",
    "        if number_of_params_with_multiple_vals == 1:\n",
    "            self.__plot_2d(param_names_with_multiple_vals[0])\n",
    "        elif number_of_params_with_multiple_vals == 2:\n",
    "            self.__plot_3d(param_names_with_multiple_vals)\n",
    "        else:\n",
    "            print(\"Plotting for this result is not supported\")\n",
    "            # TODO PCA?\n",
    "        \n",
    "    def __plot_2d(self, param_name_with_multiple_vals):\n",
    "\n",
    "        param_vals = [element['parameter_config'][param_name_with_multiple_vals] for element in self.result]\n",
    "        accuracy_result = [element['result']['accuracy'] for element in self.result]\n",
    "\n",
    "        plt.scatter(param_vals, accuracy_result)\n",
    "        plt.plot(param_vals, accuracy_result, linestyle='--')\n",
    "        plt.title(\"Accuracy per \" + \"'\" + param_name_with_multiple_vals + \"'\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(param_name_with_multiple_vals)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        df = pd.DataFrame(list(zip(param_vals, accuracy_result)), \n",
    "               columns =[param_name_with_multiple_vals, 'Accuracy']) \n",
    "        print(df)\n",
    "        \n",
    "        \n",
    "    # TODO sis  \n",
    "    def __plot_3d(self, param_name_with_multiple_vals):\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NN with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nnpt = NeuralNetworkParameterTester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpt.set_number_of_hidden_layers(2)\n",
    "nnpt.set_number_of_units_per_hidden_layer([2, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_hidden_layers': [2],\n",
       " 'number_of_units_per_hidden_layer': [2, 5, 6],\n",
       " 'epochs': [100],\n",
       " 'batch_size': [64],\n",
       " 'activation_function': ['relu'],\n",
       " 'loss_function': ['categorical_crossentropy'],\n",
       " 'optimizer': ['sgd']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.parameter_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_hidden_layers': [2],\n",
       " 'number_of_units_per_hidden_layer': [2, 5, 6],\n",
       " 'epochs': [100],\n",
       " 'batch_size': [64],\n",
       " 'activation_function': ['relu'],\n",
       " 'loss_function': ['categorical_crossentropy'],\n",
       " 'optimizer': ['sgd']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.parameter_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Fab\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "26329/26329 [==============================] - 1s 27us/step - loss: 2.3979 - acc: 0.0897\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3979 - acc: 0.0941\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3979 - acc: 0.0914\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3979 - acc: 0.0924\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3979 - acc: 0.0905\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3979 - acc: 0.0937\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3979 - acc: 0.0978\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3978 - acc: 0.0979\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3978 - acc: 0.0996\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3978 - acc: 0.1010\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3978 - acc: 0.0981\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3978 - acc: 0.1005\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3978 - acc: 0.1007\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3978 - acc: 0.0957\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3977 - acc: 0.1068\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3977 - acc: 0.1004\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3976 - acc: 0.1093\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3976 - acc: 0.1003\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3975 - acc: 0.1103\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3974 - acc: 0.1159\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3973 - acc: 0.1167\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3971 - acc: 0.1132\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3968 - acc: 0.1108\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3964 - acc: 0.1243\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3957 - acc: 0.1165\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3945 - acc: 0.1252\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3924 - acc: 0.1406\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3877 - acc: 0.1613\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3748 - acc: 0.1423\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3275 - acc: 0.1529\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.2165 - acc: 0.1721\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.0813 - acc: 0.1890\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.9583 - acc: 0.2023\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.8694 - acc: 0.2161\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.8017 - acc: 0.2290\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.7470 - acc: 0.2806\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.7002 - acc: 0.3119\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.6583 - acc: 0.3363\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.6191 - acc: 0.3544\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5821 - acc: 0.3650\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5454 - acc: 0.3794\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5109 - acc: 0.3857\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4768 - acc: 0.3971\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4475 - acc: 0.4048\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4216 - acc: 0.4105\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4021 - acc: 0.4149\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3875 - acc: 0.4152\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3699 - acc: 0.4179\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3553 - acc: 0.4204\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3455 - acc: 0.4179\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3333 - acc: 0.4161\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3251 - acc: 0.4172\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3184 - acc: 0.4124\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3140 - acc: 0.4167\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3006 - acc: 0.4124\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2956 - acc: 0.4155\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2824 - acc: 0.4183\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2807 - acc: 0.4172\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2729 - acc: 0.4160\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2664 - acc: 0.4186\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2584 - acc: 0.4209\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2549 - acc: 0.4194\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2470 - acc: 0.4239\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2412 - acc: 0.4212\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2344 - acc: 0.4296\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2419 - acc: 0.4189\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2322 - acc: 0.4211\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2305 - acc: 0.4212\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2206 - acc: 0.4266\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2191 - acc: 0.4262\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2158 - acc: 0.4227\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2101 - acc: 0.4244\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2086 - acc: 0.4271\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1949 - acc: 0.4360\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2052 - acc: 0.4293\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1891 - acc: 0.4339\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1878 - acc: 0.4293\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1880 - acc: 0.4325\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1822 - acc: 0.4316\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1818 - acc: 0.4299\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1805 - acc: 0.4344\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1786 - acc: 0.4336\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1695 - acc: 0.4378\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1686 - acc: 0.4340\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1672 - acc: 0.4351\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1694 - acc: 0.4320\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1628 - acc: 0.4389\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1582 - acc: 0.4358\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1585 - acc: 0.4298\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1566 - acc: 0.4362\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1569 - acc: 0.4352\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1504 - acc: 0.4400\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1477 - acc: 0.4418\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1487 - acc: 0.4385\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1477 - acc: 0.4380\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1417 - acc: 0.4390\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1325 - acc: 0.4472\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1374 - acc: 0.4408\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1322 - acc: 0.4458\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1403 - acc: 0.4393\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 28us/step - loss: 2.2988 - acc: 0.1383\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.1604 - acc: 0.1846\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.0548 - acc: 0.2132\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.9255 - acc: 0.2656\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.8446 - acc: 0.3164\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.7895 - acc: 0.3452\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.7397 - acc: 0.3678\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.6856 - acc: 0.4016\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.6099 - acc: 0.4277\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4992 - acc: 0.4540\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.3832 - acc: 0.4663\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.2933 - acc: 0.4925\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.2266 - acc: 0.5190\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.1720 - acc: 0.5364\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1280 - acc: 0.5485\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.0918 - acc: 0.5617\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.0625 - acc: 0.5715\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.0364 - acc: 0.5861\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.0081 - acc: 0.6023\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.9769 - acc: 0.6165\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.9495 - acc: 0.6171\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.9298 - acc: 0.6290\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.9135 - acc: 0.6320\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.8991 - acc: 0.6373\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8854 - acc: 0.6456: 0s - loss: 0.8683 - acc:\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.8732 - acc: 0.6514\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.8621 - acc: 0.6537\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8514 - acc: 0.6571\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8421 - acc: 0.6593\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8330 - acc: 0.6636\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8243 - acc: 0.6654\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8169 - acc: 0.6685\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8109 - acc: 0.6698\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8034 - acc: 0.6722\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7973 - acc: 0.6731\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7916 - acc: 0.6748\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7863 - acc: 0.6775\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7809 - acc: 0.6818\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7758 - acc: 0.6828\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7707 - acc: 0.6851\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7660 - acc: 0.6871\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7609 - acc: 0.6883\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7556 - acc: 0.6914\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7502 - acc: 0.6938\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7455 - acc: 0.6968\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7400 - acc: 0.7090\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7352 - acc: 0.7175\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7283 - acc: 0.7221\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7227 - acc: 0.7229\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7195 - acc: 0.7247\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7160 - acc: 0.7235\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7066 - acc: 0.7275\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6990 - acc: 0.7331\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6923 - acc: 0.7362\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6843 - acc: 0.7362\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6756 - acc: 0.7398\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6671 - acc: 0.7415\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6589 - acc: 0.7481\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6486 - acc: 0.7559\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6417 - acc: 0.7619\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6342 - acc: 0.7644\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6254 - acc: 0.7688\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.6213 - acc: 0.7681\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6141 - acc: 0.7715\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6086 - acc: 0.7728\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6032 - acc: 0.7734\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5971 - acc: 0.7758\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5921 - acc: 0.7789\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5842 - acc: 0.7820\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5793 - acc: 0.7844\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5727 - acc: 0.7861\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5669 - acc: 0.7907\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5620 - acc: 0.7908\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5567 - acc: 0.7914\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5534 - acc: 0.7935\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5513 - acc: 0.7943\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5427 - acc: 0.7968\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5391 - acc: 0.7983\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5353 - acc: 0.7982\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5321 - acc: 0.7984\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5310 - acc: 0.7996\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5262 - acc: 0.8008\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5231 - acc: 0.8017\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5168 - acc: 0.8051\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5162 - acc: 0.8060\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.5098 - acc: 0.8094\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5056 - acc: 0.8133\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5031 - acc: 0.8145\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5010 - acc: 0.8144\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4933 - acc: 0.8186\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4879 - acc: 0.8200\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5151 - acc: 0.8163\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4798 - acc: 0.8238\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4791 - acc: 0.8237\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4723 - acc: 0.8248\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4691 - acc: 0.8279\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4655 - acc: 0.8290\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4604 - acc: 0.8319\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4563 - acc: 0.8352\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4508 - acc: 0.8399\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 31us/step - loss: 2.4023 - acc: 0.0941\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.2983 - acc: 0.1978\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.0636 - acc: 0.2488\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.8792 - acc: 0.2893\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.6898 - acc: 0.3543\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.4464 - acc: 0.4166\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.1947 - acc: 0.4807\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.0402 - acc: 0.5085\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.9459 - acc: 0.5584\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.8833 - acc: 0.5895\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.8373 - acc: 0.6124\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.8029 - acc: 0.6386\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.7756 - acc: 0.6598\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.7516 - acc: 0.6751\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7224 - acc: 0.6923\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6905 - acc: 0.7083\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.6647 - acc: 0.7206\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.6416 - acc: 0.7350\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.6119 - acc: 0.7556\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5809 - acc: 0.7731\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5422 - acc: 0.7870\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - ETA: 0s - loss: 0.5043 - acc: 0.801 - 0s 15us/step - loss: 0.5032 - acc: 0.8027\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4666 - acc: 0.8205\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4327 - acc: 0.8359\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4025 - acc: 0.8493\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3738 - acc: 0.8602\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3517 - acc: 0.8684\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3321 - acc: 0.8750\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3136 - acc: 0.8832\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3000 - acc: 0.8899\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2891 - acc: 0.8929\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2811 - acc: 0.8974\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2730 - acc: 0.9006\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2640 - acc: 0.9041\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2597 - acc: 0.9051\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2541 - acc: 0.9078\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2493 - acc: 0.9095\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2451 - acc: 0.9102\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2427 - acc: 0.9120\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2388 - acc: 0.9131\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2356 - acc: 0.9137\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2342 - acc: 0.9152\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2319 - acc: 0.9163\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2307 - acc: 0.9180\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2279 - acc: 0.9181\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2257 - acc: 0.9184\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2257 - acc: 0.9177\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2239 - acc: 0.9188\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2202 - acc: 0.9214\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2201 - acc: 0.9215\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2203 - acc: 0.9218\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2200 - acc: 0.9215\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2187 - acc: 0.9221\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2161 - acc: 0.9226\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2159 - acc: 0.9232\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2157 - acc: 0.9224\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2134 - acc: 0.9248\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2112 - acc: 0.9259\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2105 - acc: 0.9249\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2101 - acc: 0.9266\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2091 - acc: 0.9263\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2083 - acc: 0.9265\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2068 - acc: 0.9270\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2057 - acc: 0.9286\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2052 - acc: 0.9286\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2039 - acc: 0.9286\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2041 - acc: 0.9283\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2026 - acc: 0.9295\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2019 - acc: 0.9284\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2004 - acc: 0.9306\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2002 - acc: 0.9287\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1993 - acc: 0.9296\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1984 - acc: 0.9303\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1992 - acc: 0.9292\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1980 - acc: 0.9313\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1961 - acc: 0.9308\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1958 - acc: 0.9313\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1929 - acc: 0.9329\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1931 - acc: 0.9333\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1919 - acc: 0.9318\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1912 - acc: 0.9323\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1905 - acc: 0.9342\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1897 - acc: 0.9324\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1884 - acc: 0.9335\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1895 - acc: 0.9338\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1859 - acc: 0.9344\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1839 - acc: 0.9356\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1815 - acc: 0.9358\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1794 - acc: 0.9363\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1791 - acc: 0.9368\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1773 - acc: 0.9366\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1749 - acc: 0.9380\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1738 - acc: 0.9380\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1724 - acc: 0.9406\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1714 - acc: 0.9393\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1692 - acc: 0.9398\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1696 - acc: 0.9403\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1685 - acc: 0.9404\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1661 - acc: 0.9412\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1669 - acc: 0.9409\n"
     ]
    }
   ],
   "source": [
    "nnpt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parameter_config': {'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_hidden_layer': 2,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x1ca93c54f08>,\n",
       "   'accuracy': 0.39576213260423787}},\n",
       " {'parameter_config': {'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_hidden_layer': 5,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x1ca9f28c7c8>,\n",
       "   'accuracy': 0.7990430622009569}},\n",
       " {'parameter_config': {'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_hidden_layer': 6,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x1caa6372108>,\n",
       "   'accuracy': 0.9360902255639098}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/n\n",
      "   number_of_units_per_hidden_layer  Accuracy\n",
      "0                                 2  0.395762\n",
      "1                                 5  0.799043\n",
      "2                                 6  0.936090\n"
     ]
    }
   ],
   "source": [
    "nnpt.plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpt.reset_config()\n",
    "nnpt.set_number_of_hidden_layers([2, 4, 5])\n",
    "nnpt.set_number_of_units_per_hidden_layer(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_hidden_layers': [2, 4, 5],\n",
       " 'number_of_units_per_hidden_layer': [6],\n",
       " 'epochs': [100],\n",
       " 'batch_size': [64],\n",
       " 'activation_function': ['relu'],\n",
       " 'loss_function': ['categorical_crossentropy'],\n",
       " 'optimizer': ['sgd']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.parameter_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 30us/step - loss: 2.2847 - acc: 0.1296\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.9916 - acc: 0.2506\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.7199 - acc: 0.3017\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.4784 - acc: 0.3962\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.3041 - acc: 0.4881\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.1495 - acc: 0.5446\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.0138 - acc: 0.5732\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.9104 - acc: 0.5941\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.8399 - acc: 0.6175\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.7913 - acc: 0.6472\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.7496 - acc: 0.6725\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.7099 - acc: 0.6864\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.6731 - acc: 0.6984\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.6374 - acc: 0.7121\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.6102 - acc: 0.7225\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5839 - acc: 0.7323\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5638 - acc: 0.7434\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5443 - acc: 0.7541\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5299 - acc: 0.7608\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5163 - acc: 0.7641\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5030 - acc: 0.7704\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4896 - acc: 0.7788\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4784 - acc: 0.7851\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4689 - acc: 0.7872\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4581 - acc: 0.7936\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4469 - acc: 0.8009\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4385 - acc: 0.8027\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.4266 - acc: 0.8108\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4153 - acc: 0.8158\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4064 - acc: 0.8208\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3937 - acc: 0.8297\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3852 - acc: 0.8329\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3767 - acc: 0.8407\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3701 - acc: 0.8418\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3636 - acc: 0.8491\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3542 - acc: 0.8537\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3459 - acc: 0.8587\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3376 - acc: 0.8645\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3306 - acc: 0.8684\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.3210 - acc: 0.8749\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3111 - acc: 0.8821\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3010 - acc: 0.8891\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2868 - acc: 0.8962\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2788 - acc: 0.9017\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2686 - acc: 0.9067\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - ETA: 0s - loss: 0.2606 - acc: 0.908 - 0s 15us/step - loss: 0.2598 - acc: 0.9085\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2484 - acc: 0.9129\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2432 - acc: 0.9158\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2342 - acc: 0.9195\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2337 - acc: 0.9198\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2274 - acc: 0.9221\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2234 - acc: 0.9230\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2218 - acc: 0.9226\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2160 - acc: 0.9259\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2085 - acc: 0.9284\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2085 - acc: 0.9290\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2068 - acc: 0.9289\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2083 - acc: 0.9273\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2018 - acc: 0.9300\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2030 - acc: 0.9305\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.1982 - acc: 0.9322\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1977 - acc: 0.9336\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1981 - acc: 0.9326\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.1939 - acc: 0.9331\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.1930 - acc: 0.9341\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1921 - acc: 0.9352\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1913 - acc: 0.9344\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1900 - acc: 0.9347\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.1907 - acc: 0.9336\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1863 - acc: 0.9372\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1861 - acc: 0.9362\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1879 - acc: 0.9363\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1862 - acc: 0.9357\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1832 - acc: 0.9379\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1837 - acc: 0.9371\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1803 - acc: 0.9386\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1808 - acc: 0.9371\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1808 - acc: 0.9395\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.1778 - acc: 0.9394\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1782 - acc: 0.9396\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1779 - acc: 0.9406\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1752 - acc: 0.9399\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1728 - acc: 0.9401\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1738 - acc: 0.9407\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1716 - acc: 0.9414\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.1720 - acc: 0.9408\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1688 - acc: 0.9413\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1693 - acc: 0.9415\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1657 - acc: 0.9439\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1651 - acc: 0.9440\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1662 - acc: 0.9411\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1647 - acc: 0.9439\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1625 - acc: 0.9446\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1612 - acc: 0.9452\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1636 - acc: 0.9439\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1623 - acc: 0.9448\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1610 - acc: 0.9444\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1614 - acc: 0.9442\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1565 - acc: 0.9463\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.1582 - acc: 0.9445\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 39us/step - loss: 2.3969 - acc: 0.1098\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.3932 - acc: 0.1138\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.3858 - acc: 0.1236\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.3491 - acc: 0.1277\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.2295 - acc: 0.1610\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 2.0759 - acc: 0.1897\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.9123 - acc: 0.2234\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.8010 - acc: 0.2396\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.7212 - acc: 0.2594\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.6587 - acc: 0.2770\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.6095 - acc: 0.2886\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.5735 - acc: 0.3176\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.5472 - acc: 0.3331\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.5280 - acc: 0.3586\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.5118 - acc: 0.3519\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4983 - acc: 0.3817\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.4843 - acc: 0.3852\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.4663 - acc: 0.3955\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.4329 - acc: 0.4131\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.3441 - acc: 0.4246\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.2595 - acc: 0.4482\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.2115 - acc: 0.4713\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.1438 - acc: 0.5178\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.0529 - acc: 0.5491\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.9928 - acc: 0.5638\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.9551 - acc: 0.5670\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.9287 - acc: 0.5662\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.9127 - acc: 0.5822\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8988 - acc: 0.5864\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8856 - acc: 0.5855\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8714 - acc: 0.5923\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8605 - acc: 0.5968\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8523 - acc: 0.5985\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8413 - acc: 0.6091\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8278 - acc: 0.6298\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8140 - acc: 0.6500\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8001 - acc: 0.6551\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.7888 - acc: 0.6598\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.7719 - acc: 0.6628\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.7564 - acc: 0.6717\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.7397 - acc: 0.6819\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.7293 - acc: 0.6783\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.7112 - acc: 0.6896\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.6932 - acc: 0.6941\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.6783 - acc: 0.6998\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6618 - acc: 0.7124\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.6446 - acc: 0.7151\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6314 - acc: 0.7253\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6054 - acc: 0.7383\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.5652 - acc: 0.7683\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.5221 - acc: 0.7972\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.5003 - acc: 0.8101\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4836 - acc: 0.8208\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.4686 - acc: 0.8333\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4482 - acc: 0.8452\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3989 - acc: 0.8649\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.3624 - acc: 0.8772\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.3444 - acc: 0.8844\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.3325 - acc: 0.8885\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.3265 - acc: 0.8897\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3189 - acc: 0.8911\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3110 - acc: 0.8950\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3065 - acc: 0.8976\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3019 - acc: 0.8998\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2971 - acc: 0.9001\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2967 - acc: 0.9037\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.2918 - acc: 0.9039\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2923 - acc: 0.9012\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2828 - acc: 0.9077\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2801 - acc: 0.9082\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2800 - acc: 0.9071\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2758 - acc: 0.9099\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2701 - acc: 0.9118\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2673 - acc: 0.9132\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2648 - acc: 0.9155\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2638 - acc: 0.9166\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2577 - acc: 0.9189\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2581 - acc: 0.9176\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2556 - acc: 0.9196\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2522 - acc: 0.9204\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2502 - acc: 0.9212\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2470 - acc: 0.9221\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2453 - acc: 0.9232\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2434 - acc: 0.9259\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2406 - acc: 0.9245\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2400 - acc: 0.9262\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2380 - acc: 0.9265\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2388 - acc: 0.9261\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2356 - acc: 0.9284\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2336 - acc: 0.9292\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2294 - acc: 0.9299\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2274 - acc: 0.9321\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2262 - acc: 0.9305\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2235 - acc: 0.9318\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2221 - acc: 0.9331\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2225 - acc: 0.9333\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2215 - acc: 0.9315\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2189 - acc: 0.9326\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2217 - acc: 0.9325\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.2183 - acc: 0.9330\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 40us/step - loss: 2.4017 - acc: 0.0978\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.3973 - acc: 0.1015\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.3955 - acc: 0.1049\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.3909 - acc: 0.1124\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.3673 - acc: 0.1259\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 2.2327 - acc: 0.1425\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 2.0454 - acc: 0.1824\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.8654 - acc: 0.2331\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.7492 - acc: 0.2656\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.6657 - acc: 0.2995\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.5920 - acc: 0.3267\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.5261 - acc: 0.3505\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4683 - acc: 0.3710\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4090 - acc: 0.4233\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3458 - acc: 0.4761\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2658 - acc: 0.5075\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.1618 - acc: 0.5484\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.0286 - acc: 0.5876\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.8798 - acc: 0.6402\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7043 - acc: 0.7244\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.5421 - acc: 0.7731\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4851 - acc: 0.7905\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4451 - acc: 0.8063\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.4262 - acc: 0.8211\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3857 - acc: 0.8403\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3996 - acc: 0.8483\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3553 - acc: 0.8555\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3464 - acc: 0.8605\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3319 - acc: 0.8633\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3418 - acc: 0.8670\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3193 - acc: 0.8723\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3158 - acc: 0.8752\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3078 - acc: 0.8804\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2819 - acc: 0.8878\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2940 - acc: 0.8847\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2790 - acc: 0.8899\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2842 - acc: 0.8891\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.2656 - acc: 0.8938: 0s - loss: 0.2617 - acc\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2660 - acc: 0.8942\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.2724 - acc: 0.8935\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 1s 19us/step - loss: 0.2940 - acc: 0.8928\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 1s 19us/step - loss: 0.2617 - acc: 0.8973\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2637 - acc: 0.8970\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2462 - acc: 0.9028\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2406 - acc: 0.9031\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2400 - acc: 0.9046\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.2377 - acc: 0.9043\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 1s 20us/step - loss: 0.2486 - acc: 0.9044\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 1s 20us/step - loss: 0.2288 - acc: 0.9117\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.2210 - acc: 0.9150\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2123 - acc: 0.9164\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 1s 19us/step - loss: 0.2144 - acc: 0.9141\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.2071 - acc: 0.9185\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2130 - acc: 0.9178\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2031 - acc: 0.9191\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1943 - acc: 0.9242\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1994 - acc: 0.9218\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.1985 - acc: 0.9210\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1908 - acc: 0.9250\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1939 - acc: 0.9242\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1940 - acc: 0.9245\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1905 - acc: 0.9250\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1947 - acc: 0.9248\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1836 - acc: 0.9278\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1859 - acc: 0.9272\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1867 - acc: 0.9280\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1851 - acc: 0.9286\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1918 - acc: 0.9291\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1795 - acc: 0.9302\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1838 - acc: 0.9292\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.2015 - acc: 0.9268\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1816 - acc: 0.9308\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1867 - acc: 0.9295\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1765 - acc: 0.9332\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1742 - acc: 0.9348\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1823 - acc: 0.9304\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1754 - acc: 0.9318\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.1782 - acc: 0.9340\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.1856 - acc: 0.9315\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1725 - acc: 0.9344\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1731 - acc: 0.9347\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1768 - acc: 0.9337\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1712 - acc: 0.9351\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1712 - acc: 0.9343\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1691 - acc: 0.9338\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1703 - acc: 0.9341\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1713 - acc: 0.9352\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1725 - acc: 0.9334\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1706 - acc: 0.9360\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1703 - acc: 0.9356\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1732 - acc: 0.9340\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1710 - acc: 0.9364\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1688 - acc: 0.9361\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1695 - acc: 0.9351\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1742 - acc: 0.9328\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1706 - acc: 0.9344\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1695 - acc: 0.9354\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1680 - acc: 0.9364\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.1711 - acc: 0.9353\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.1649 - acc: 0.9377\n"
     ]
    }
   ],
   "source": [
    "nnpt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parameter_config': {'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_hidden_layer': 6,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x1cab52a9408>,\n",
       "   'accuracy': 0.8834586466165414}},\n",
       " {'parameter_config': {'number_of_hidden_layers': 4,\n",
       "   'number_of_units_per_hidden_layer': 6,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x1cab5304588>,\n",
       "   'accuracy': 0.9261790840738209}},\n",
       " {'parameter_config': {'number_of_hidden_layers': 5,\n",
       "   'number_of_units_per_hidden_layer': 6,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x1cabd328288>,\n",
       "   'accuracy': 0.9360902255639098}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/n\n",
      "   number_of_hidden_layers  Accuracy\n",
      "0                        2  0.883459\n",
      "1                        4  0.926179\n",
      "2                        5  0.936090\n"
     ]
    }
   ],
   "source": [
    "nnpt.plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot Matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
