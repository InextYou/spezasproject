{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"../data/Component_Faults_Data.csv\"\n",
    "df = pd.read_csv(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, :48].values\n",
    "y = df[\"class\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newer Solution for testing NN-Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "    \n",
    "    \n",
    "class NeuralNetworkParameterTester:\n",
    "\n",
    "    # params for building model\n",
    "    config = {\n",
    "        'input_layer_dim': 48,\n",
    "        'output_layer_dim': 11,\n",
    "        'number_of_hidden_layers': 1,\n",
    "        'number_of_units_per_layer': 10,\n",
    "        'epochs': 100,\n",
    "        'batch_size': 64,\n",
    "        'activation_function': 'relu',\n",
    "        'loss_function': 'categorical_crossentropy',\n",
    "        'optimizer': 'sgd'}\n",
    "\n",
    "    \n",
    "    test_param_name = None  # Name of the div parameter\n",
    "    test_param_val = None  # Values of the div parameter\n",
    "    \n",
    "    result = []  # Result of the test\n",
    "    \n",
    "    # schema of result:\n",
    "    #\n",
    "    # [\n",
    "    #    [\n",
    "    #        'test_param_val': 1,\n",
    "    #        'params': [\n",
    "    #            'input_layer_dim': 48,\n",
    "    #            'output_layer_dim': 11,\n",
    "    #            'activation_function': 'relu',\n",
    "    #            'loss_function': 'mean_squared_error',\n",
    "    #            'optimizer': 'sgd',\n",
    "    #            'number_of_hidden_layers': 1,\n",
    "    #            'number_of_units_per_layer': 10]\n",
    "    #        'result': [\n",
    "    #            'model': model,\n",
    "    #            'acurracy': 0.923\n",
    "    #        ]\n",
    "    #    ],\n",
    "    #    [\n",
    "    #        'test_param_val': 2,\n",
    "    #        'params': [\n",
    "    #            'input_layer_dim': 48,\n",
    "    #            'output_layer_dim': 11,\n",
    "    #            'activation_function': 'relu',\n",
    "    #            'loss_function': 'mean_squared_error',\n",
    "    #            'optimizer': 'sgd',\n",
    "    #            'number_of_hidden_layers': 2,\n",
    "    #            'number_of_units_per_layer': 10]\n",
    "    #        'result': [\n",
    "    #            'model': model,\n",
    "    #            'acurracy': 0.923\n",
    "    #        ]\n",
    "    #    ],\n",
    "    #   [...........]\n",
    "    # ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, test_param_name, test_param_val):\n",
    "        \n",
    "        # 'param_name' and 'param_val' must be of right type and not None\n",
    "        # if this is the case, they will be set\n",
    "        \n",
    "        if test_param_name is not None and isinstance(test_param_name, str):\n",
    "            self.test_param_name = test_param_name\n",
    "            if test_param_val is not None and (isinstance(test_param_val, int) or isinstance(test_param_val, list)):\n",
    "                self.test_param_val = test_param_val\n",
    "                self.config[self.test_param_name] = self.test_param_val\n",
    "            else:\n",
    "                print(\"'test_param_val' must be of type int or list\")\n",
    "                sys.exit(0)\n",
    "        else:\n",
    "            print(\"'param_name' must be of type str\")\n",
    "            sys.exit(0)\n",
    "        #self.result.append({\"test_param_name\": self.test_param_name})\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        for val in self.config[self.test_param_name]:\n",
    "            \n",
    "            print(val)\n",
    "            \n",
    "            # prepare config for individual test\n",
    "            test_config = self.config  \n",
    "            test_config[self.test_param_name] = val\n",
    "        \n",
    "            model = self.__build(test_config)\n",
    "            trained_model, history = self.__train(test_config, model)\n",
    "            accuracy = self.__test(trained_model)\n",
    "            \n",
    "            # save result\n",
    "            self.result.append({\"test_param_val\": val, \n",
    "                                'params': test_config.copy(), \n",
    "                                \"result\": {'model': trained_model, \n",
    "                                           'accuracy': accuracy}})\n",
    "\n",
    "    def __build(self, test_config):\n",
    "\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import Dense\n",
    "\n",
    "        model = Sequential()        \n",
    "        # Input layer\n",
    "        model.add(Dense(test_config['number_of_units_per_layer'], \n",
    "                        input_dim=test_config['input_layer_dim'], \n",
    "                        activation=test_config['activation_function']))\n",
    "        # Hidden layer\n",
    "        for i in range(test_config['number_of_hidden_layers']):\n",
    "            model.add(Dense(test_config['number_of_units_per_layer'], \n",
    "                            activation=test_config['activation_function']))\n",
    "        # Output layer\n",
    "        model.add(Dense(test_config['output_layer_dim'], \n",
    "                        activation=\"softmax\"))\n",
    "\n",
    "        model.compile(loss=test_config['loss_function'], \n",
    "                      optimizer=test_config['optimizer'], \n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def __train(self, test_config, model):\n",
    "        # xtrain and ytrain are from preprocessing\n",
    "        history = model.fit(x_train, \n",
    "                            y_train, \n",
    "                            epochs=test_config['epochs'], \n",
    "                            batch_size=test_config['batch_size'])             \n",
    "        return model, history\n",
    "    \n",
    "    \n",
    "    # TODO: look at this method more closely. So far just copy paste\n",
    "    @staticmethod\n",
    "    def __test(model):\n",
    "        y_pred = model.predict(x_test)\n",
    "        # Converting predictions to label\n",
    "        pred = list()\n",
    "        for i in range(len(y_pred)):\n",
    "            pred.append(np.argmax(y_pred[i]))\n",
    "        # Converting one hot encoded test label to label\n",
    "        test = list()\n",
    "        for i in range(len(y_test)):\n",
    "            test.append(np.argmax(y_test[i]))\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score(pred, test)\n",
    "        return accuracy\n",
    "                                    \n",
    "                                    \n",
    "    # Setter methods for setting single parameters\n",
    "\n",
    "    def set_number_of_hidden_layers(self, val):\n",
    "        self.config[\"number_of_hidden_layers\"] = val\n",
    "        \n",
    "    def set_number_of_units_per_layer(self, val):\n",
    "        self.config[\"number_of_units_per_layer\"] = val\n",
    "        \n",
    "    def set_activation_function(self, val):\n",
    "        self.config[\"activation_function\"] = val\n",
    "        \n",
    "    def set_epochs(self, val):\n",
    "        self.config[\"epochs\"] = val\n",
    "        \n",
    "    def set_batch_size(self, val):\n",
    "        self.config[\"batch_size\"] = val\n",
    "        \n",
    "    def set_loss_function(self, val):\n",
    "        self.config[\"loss_function\"] = val\n",
    "        \n",
    "    def set_optimizer(self, val):\n",
    "        self.config[\"optimizer\"] = val\n",
    "        \n",
    "    def reset_config(self):\n",
    "        config = {\n",
    "            'input_layer_dim': 48,\n",
    "            'output_layer_dim': 11,\n",
    "            'number_of_hidden_layers': 1,\n",
    "            'number_of_units_per_layer': 10,\n",
    "            'epochs': 100,\n",
    "            'batch_size': 64,\n",
    "            'activation_function': 'relu',\n",
    "            'loss_function': 'categorical_crossentropy',\n",
    "            'optimizer': 'sgd'}\n",
    "        \n",
    "        config[self.test_param_name] = self.test_param_val\n",
    "        self.config = config\n",
    "        \n",
    "    # Plot result\n",
    "    \n",
    "    def plot_result(self, dim=2):\n",
    "        if dim == 2:\n",
    "            self.__plot_2d()\n",
    "\n",
    "    def __plot_2d(self):\n",
    "\n",
    "        # TODO: improve plot\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        test_param_val = [element['test_param_val'] for element in self.result]\n",
    "        accuracy_result = [element['result']['accuracy'] for element in self.result]\n",
    "\n",
    "        plt.scatter(test_param_val, accuracy_result)\n",
    "        plt.plot(test_param_val, accuracy_result, linestyle='--')\n",
    "        plt.title(\"Accuracy per \" + \"'\" + self.test_param_name + \"'\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(self.test_param_name)\n",
    "        plt.show()\n",
    "        \n",
    "        print('\"test_param_val\":\\t' test_param_val)\n",
    "        print('\"accuracy_result\":\\t' accuracy_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NN with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nnpt = NeuralNetworkParameterTester(test_param_name=\"number_of_units_per_layer\", test_param_val=[4, 8, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_layer_dim': 48,\n",
       " 'output_layer_dim': 11,\n",
       " 'number_of_hidden_layers': 1,\n",
       " 'number_of_units_per_layer': [4, 8, 16],\n",
       " 'epochs': 100,\n",
       " 'batch_size': 64,\n",
       " 'activation_function': 'relu',\n",
       " 'loss_function': 'categorical_crossentropy',\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpt.set_number_of_hidden_layers(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_layer_dim': 48,\n",
       " 'output_layer_dim': 11,\n",
       " 'number_of_hidden_layers': 2,\n",
       " 'number_of_units_per_layer': [4, 8, 16],\n",
       " 'epochs': 100,\n",
       " 'batch_size': 64,\n",
       " 'activation_function': 'relu',\n",
       " 'loss_function': 'categorical_crossentropy',\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 2s 78us/step - loss: 2.3306 - acc: 0.1318\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 2.2009 - acc: 0.1525\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 2.1529 - acc: 0.2008\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 2.1169 - acc: 0.2148\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 2.0644 - acc: 0.2364\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.9658 - acc: 0.2450\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 1.8573 - acc: 0.2463\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.8075 - acc: 0.2516\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.7764 - acc: 0.2554: 0s - loss: 1.7856 - \n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.7536 - acc: 0.2578\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.7362 - acc: 0.2683\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.7225 - acc: 0.2658\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.7115 - acc: 0.2858\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.7019 - acc: 0.2941\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.6925 - acc: 0.3015\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.6810 - acc: 0.3050\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.6632 - acc: 0.3146\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 1.6394 - acc: 0.3253\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.6165 - acc: 0.3353\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.5957 - acc: 0.3481\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.5744 - acc: 0.3500\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.5518 - acc: 0.3602\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.5305 - acc: 0.3639\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.5113 - acc: 0.3684\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.4936 - acc: 0.3751\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.4754 - acc: 0.3775\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.4565 - acc: 0.3847\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.4351 - acc: 0.3875\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.4076 - acc: 0.4007\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.3755 - acc: 0.4106\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.3447 - acc: 0.4168\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 1.3193 - acc: 0.4199\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.2964 - acc: 0.4265\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.2768 - acc: 0.4326\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.2591 - acc: 0.4361\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.2428 - acc: 0.4429\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.2282 - acc: 0.4433\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.2160 - acc: 0.4465\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 1.2049 - acc: 0.4484\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1938 - acc: 0.4488\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 1.1833 - acc: 0.4519\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1745 - acc: 0.4515\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1655 - acc: 0.4538\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1561 - acc: 0.4566\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1479 - acc: 0.4601\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1414 - acc: 0.4576\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1323 - acc: 0.4615\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1273 - acc: 0.4587\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1196 - acc: 0.4608\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.1121 - acc: 0.4613\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.1075 - acc: 0.4664\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0963 - acc: 0.4677\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0916 - acc: 0.4729\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0908 - acc: 0.4766\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0831 - acc: 0.4795\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.0789 - acc: 0.4835\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 1.0746 - acc: 0.4829\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0706 - acc: 0.5029\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0641 - acc: 0.5018\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0642 - acc: 0.5026\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.0615 - acc: 0.5014\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0592 - acc: 0.5045\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0540 - acc: 0.5086\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0532 - acc: 0.5061\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0525 - acc: 0.5126\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0451 - acc: 0.5080\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0489 - acc: 0.5100\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0559 - acc: 0.5078\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0443 - acc: 0.5100\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0457 - acc: 0.5140\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 1.0517 - acc: 0.5175\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 1.0471 - acc: 0.5239\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0426 - acc: 0.5348\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.0383 - acc: 0.5410\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 1s 25us/step - loss: 1.0539 - acc: 0.5454\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 1.0347 - acc: 0.5480\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 1s 31us/step - loss: 1.0171 - acc: 0.5474\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 1s 28us/step - loss: 1.0192 - acc: 0.5514\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.0123 - acc: 0.5533\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - ETA: 0s - loss: 1.0104 - acc: 0.550 - 1s 22us/step - loss: 1.0093 - acc: 0.5513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 1s 25us/step - loss: 1.0140 - acc: 0.5553\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0052 - acc: 0.5619\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.9997 - acc: 0.5647: 0s - loss: 0.9973 - acc: 0.\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.9933 - acc: 0.5682\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0021 - acc: 0.5679\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 1.0121 - acc: 0.5643\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.0077 - acc: 0.5638\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.9939 - acc: 0.5733\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 1s 27us/step - loss: 0.9934 - acc: 0.5674\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 1s 25us/step - loss: 0.9740 - acc: 0.5796\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.9658 - acc: 0.5946\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.9445 - acc: 0.5979\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.9804 - acc: 0.6132\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.9230 - acc: 0.6275\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.9139 - acc: 0.6296\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.9080 - acc: 0.6435\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.8998 - acc: 0.6491\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.8985 - acc: 0.6540\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.8930 - acc: 0.6617\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.8830 - acc: 0.6693\n",
      "8\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 2s 79us/step - loss: 2.3902 - acc: 0.1163\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 2.2579 - acc: 0.1954\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 2.0873 - acc: 0.2678\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.8371 - acc: 0.3217\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 1.4880 - acc: 0.4413\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.1154 - acc: 0.5968\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 1s 25us/step - loss: 0.8727 - acc: 0.6880\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 1s 26us/step - loss: 0.7416 - acc: 0.7301\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.6587 - acc: 0.7616\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.6005 - acc: 0.7852\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 1s 25us/step - loss: 0.5540 - acc: 0.8047\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.5132 - acc: 0.8212\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.4788 - acc: 0.8349\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 1s 26us/step - loss: 0.4476 - acc: 0.8457\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 1s 26us/step - loss: 0.4204 - acc: 0.8529\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.3951 - acc: 0.8606\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 1s 30us/step - loss: 0.3687 - acc: 0.8686\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 1s 34us/step - loss: 0.3428 - acc: 0.8776\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 1s 26us/step - loss: 0.3178 - acc: 0.8866\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.2956 - acc: 0.8951\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2778 - acc: 0.9020\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2645 - acc: 0.9084\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2542 - acc: 0.9113\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2438 - acc: 0.9131\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 1s 25us/step - loss: 0.2364 - acc: 0.9169\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2292 - acc: 0.9197\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 1s 26us/step - loss: 0.2226 - acc: 0.9226\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2185 - acc: 0.9257\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2114 - acc: 0.9268\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2077 - acc: 0.9257\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2034 - acc: 0.9289\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1995 - acc: 0.9311\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1957 - acc: 0.9316\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1924 - acc: 0.9342\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1895 - acc: 0.9330\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 1s 25us/step - loss: 0.1883 - acc: 0.9350\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 1s 26us/step - loss: 0.1847 - acc: 0.9362\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1817 - acc: 0.9371\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1779 - acc: 0.9388\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1761 - acc: 0.9395\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1747 - acc: 0.9395\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1728 - acc: 0.9404\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1709 - acc: 0.9402\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1688 - acc: 0.9422\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1670 - acc: 0.9417\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1658 - acc: 0.9419\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1640 - acc: 0.9422\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1621 - acc: 0.9432\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1605 - acc: 0.9435\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1593 - acc: 0.9432\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1578 - acc: 0.9444\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1573 - acc: 0.9447\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1561 - acc: 0.9456\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1547 - acc: 0.9462\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1527 - acc: 0.9465\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1524 - acc: 0.9463\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1516 - acc: 0.9466\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1507 - acc: 0.9474\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1491 - acc: 0.9477\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1496 - acc: 0.9484\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1468 - acc: 0.9489\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1471 - acc: 0.9487\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1460 - acc: 0.9492\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1443 - acc: 0.9506\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1444 - acc: 0.9487\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1430 - acc: 0.9496\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1410 - acc: 0.9502\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1413 - acc: 0.9509\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1400 - acc: 0.9509\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1400 - acc: 0.9514\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1382 - acc: 0.9509\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1364 - acc: 0.9526\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1366 - acc: 0.9526\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1358 - acc: 0.9512\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1356 - acc: 0.9534\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1344 - acc: 0.9525\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1328 - acc: 0.9525\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1350 - acc: 0.9532\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1351 - acc: 0.9531\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1320 - acc: 0.9532\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1316 - acc: 0.9541\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1316 - acc: 0.9543\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1300 - acc: 0.9537\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 1s 25us/step - loss: 0.1312 - acc: 0.9535\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 1s 30us/step - loss: 0.1314 - acc: 0.9543\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1294 - acc: 0.9539\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1276 - acc: 0.9553\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1273 - acc: 0.9554\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1280 - acc: 0.9552\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1257 - acc: 0.9550\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1263 - acc: 0.9555\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1264 - acc: 0.9556\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1262 - acc: 0.9554\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1266 - acc: 0.9550\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1252 - acc: 0.9555\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1240 - acc: 0.9561\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1237 - acc: 0.9567\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1237 - acc: 0.9565\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.1230 - acc: 0.9561\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1229 - acc: 0.9561\n",
      "16\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 2s 82us/step - loss: 2.2465 - acc: 0.1815\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.8306 - acc: 0.3604\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.4055 - acc: 0.4907\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 1.0948 - acc: 0.5867\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.8699 - acc: 0.6702\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.6717 - acc: 0.7463\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.5264 - acc: 0.8061\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.4331 - acc: 0.8412\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.3711 - acc: 0.8680\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.3242 - acc: 0.8857\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2896 - acc: 0.8994\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2633 - acc: 0.9110\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2439 - acc: 0.9194\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2280 - acc: 0.9239\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2152 - acc: 0.9309\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.2041 - acc: 0.9346\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1938 - acc: 0.9372\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1843 - acc: 0.9410\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1775 - acc: 0.9444\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1705 - acc: 0.9461\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1649 - acc: 0.9493\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1593 - acc: 0.9500\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1543 - acc: 0.9521\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1504 - acc: 0.9528\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1455 - acc: 0.9551\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1421 - acc: 0.9556\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1378 - acc: 0.9578\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1350 - acc: 0.9580\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1318 - acc: 0.9594\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1289 - acc: 0.9604\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1257 - acc: 0.9607\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1239 - acc: 0.9619\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1205 - acc: 0.9620\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1180 - acc: 0.9635\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1160 - acc: 0.9640\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1146 - acc: 0.9641\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1118 - acc: 0.9652\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1099 - acc: 0.9648\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.1083 - acc: 0.9661\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 1s 27us/step - loss: 0.1059 - acc: 0.9662\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1046 - acc: 0.9670\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.1031 - acc: 0.9672\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1018 - acc: 0.9681\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.1006 - acc: 0.9683\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0994 - acc: 0.9698\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0984 - acc: 0.9692\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0970 - acc: 0.9699\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0954 - acc: 0.9701\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0946 - acc: 0.9705\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.0939 - acc: 0.9705\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0928 - acc: 0.9707\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0909 - acc: 0.9716\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0902 - acc: 0.9717\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0898 - acc: 0.9721\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0885 - acc: 0.9724\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0876 - acc: 0.9724\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0866 - acc: 0.9727\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0860 - acc: 0.9733\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0854 - acc: 0.9739\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.0841 - acc: 0.9742\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0835 - acc: 0.9744\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0828 - acc: 0.9750\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0828 - acc: 0.9746\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0816 - acc: 0.9754\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0808 - acc: 0.9747\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0806 - acc: 0.9753\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0795 - acc: 0.9759\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0783 - acc: 0.9754\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0779 - acc: 0.9760\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0785 - acc: 0.9749\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0772 - acc: 0.9762\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0770 - acc: 0.9754\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0761 - acc: 0.9767\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0755 - acc: 0.9765\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0746 - acc: 0.9774\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0747 - acc: 0.9766\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0733 - acc: 0.9765\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0732 - acc: 0.9772\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0730 - acc: 0.9774\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0719 - acc: 0.9785\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 1s 24us/step - loss: 0.0722 - acc: 0.9775\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0711 - acc: 0.9772\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0710 - acc: 0.9784\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0699 - acc: 0.9784\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0700 - acc: 0.9779\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0686 - acc: 0.9790\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0688 - acc: 0.9781\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0684 - acc: 0.9796\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0679 - acc: 0.9794\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0668 - acc: 0.9798\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0674 - acc: 0.9796\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0665 - acc: 0.9791\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0668 - acc: 0.9793\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 1s 22us/step - loss: 0.0662 - acc: 0.9791\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0658 - acc: 0.9795\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0648 - acc: 0.9798\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0644 - acc: 0.9801\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0643 - acc: 0.9797\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0636 - acc: 0.9802\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.0630 - acc: 0.9799\n"
     ]
    }
   ],
   "source": [
    "nnpt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test_param_val': 4,\n",
       "  'params': {'input_layer_dim': 48,\n",
       "   'output_layer_dim': 11,\n",
       "   'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_layer': 4,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x201f3b001c8>,\n",
       "   'accuracy': 0.6797676008202324}},\n",
       " {'test_param_val': 8,\n",
       "  'params': {'input_layer_dim': 48,\n",
       "   'output_layer_dim': 11,\n",
       "   'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_layer': 8,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x201f3b8fc48>,\n",
       "   'accuracy': 0.950786056049214}},\n",
       " {'test_param_val': 16,\n",
       "  'params': {'input_layer_dim': 48,\n",
       "   'output_layer_dim': 11,\n",
       "   'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_layer': 16,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x201f3c06c88>,\n",
       "   'accuracy': 0.9760765550239234}}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 8, 16]\n",
      "[0.6797676008202324, 0.950786056049214, 0.9760765550239234]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnpt.plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot Matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
