{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "path_to_file = \"../data/Component_Faults_Data.csv\"\n",
    "df = pd.read_csv(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "x = df.iloc[:, :48].values\n",
    "y = df[\"class\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newer Solution for testing NN-Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for class\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt    \n",
    "import itertools\n",
    "        \n",
    "\n",
    "\"\"\" \n",
    "    The following class helps in streamlining the building, training, and testing of a Neural Network (NN)\n",
    "    With it, we can see the effect on the result for changing a single parameter \n",
    "    So we only have to provide the name of the parameter we have to change, and the values we want to test it with\n",
    "\"\"\"\n",
    "class NeuralNetworkParameterTester:\n",
    "\n",
    "    # The config holds all the changeable parameters for building, training and testing the NN\n",
    "    parameter_config = {\n",
    "                'number_of_hidden_layers': [1],\n",
    "                'number_of_units_per_hidden_layer': [10],\n",
    "                'epochs': [100],\n",
    "                'batch_size': [64],\n",
    "                'activation_function': ['relu'],\n",
    "                'loss_function': ['categorical_crossentropy'],\n",
    "                'optimizer': ['sgd']}\n",
    "    \n",
    "    # Result of the test\n",
    "    result = []\n",
    "    \n",
    "    \"\"\" \n",
    "        If you want to test your parameters, then you have to call this class\n",
    "    \"\"\"       \n",
    "    def run(self):\n",
    "        \n",
    "        # Reset result\n",
    "        self.result = []\n",
    "        \n",
    "        # Build all possible parameter combinations and  ...\n",
    "        for config in self.__get_all_config_combinations():\n",
    "            # ... build the NN-model for it\n",
    "            model = self.__build(config)\n",
    "            # ... train the NN-model \n",
    "            trained_model, history = self.__train(config, model)\n",
    "            # ... test the NN-model and get the accuracy score\n",
    "            accuracy = self.__test(trained_model)\n",
    "\n",
    "            # Save the result\n",
    "            self.result.append({'parameter_config': config.copy(), \n",
    "                                \"result\": {'model': trained_model, \n",
    "                                           'accuracy': accuracy}})\n",
    "            \n",
    "    \"\"\" \n",
    "        The following method builds all combinations of your parameter-config\n",
    "    \"\"\"          \n",
    "    def __get_all_config_combinations(self):\n",
    "\n",
    "        raw_combinations = list(itertools.product(*(self.parameter_config[parameter] for parameter in self.parameter_config)))\n",
    "\n",
    "        config_combinations_list = []\n",
    "        for combination in raw_combinations:\n",
    "            c = {\n",
    "                'number_of_hidden_layers': combination[0],\n",
    "                'number_of_units_per_hidden_layer': combination[1],\n",
    "                'epochs': combination[2],\n",
    "                'batch_size': combination[3],\n",
    "                'activation_function': combination[4],\n",
    "                'loss_function': combination[5],\n",
    "                'optimizer': combination[6]}\n",
    "            \n",
    "            config_combinations_list.append(c)\n",
    "        \n",
    "        return config_combinations_list\n",
    "    \n",
    "    \"\"\" \n",
    "        The following method builds the NN-Model\n",
    "    \"\"\"   \n",
    "    def __build(self, config):\n",
    "\n",
    "        # Sequential model (Basic NN)\n",
    "        model = Sequential()        \n",
    "        # Building of input layer\n",
    "        model.add(Dense(config['number_of_units_per_hidden_layer'], \n",
    "                        input_dim=48, \n",
    "                        activation=config['activation_function']))\n",
    "        # Building of hidden layer(s)\n",
    "        for i in range(config['number_of_hidden_layers']):\n",
    "            model.add(Dense(config['number_of_units_per_hidden_layer'], \n",
    "                            activation=config['activation_function']))\n",
    "        # Building of output layer\n",
    "        model.add(Dense(11, activation=\"softmax\"))\n",
    "        # ?\n",
    "        model.compile(loss=config['loss_function'], \n",
    "                      optimizer=config['optimizer'], \n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    \"\"\" \n",
    "        The following method trains the NN-Model\n",
    "    \"\"\"   \n",
    "    def __train(self, config, model):\n",
    "        # xtrain and ytrain is the data from preprocessing\n",
    "        history = model.fit(x_train, \n",
    "                            y_train, \n",
    "                            epochs=config['epochs'], \n",
    "                            batch_size=config['batch_size'])  \n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    \"\"\" \n",
    "        The following method tests the NN-Model\n",
    "    \"\"\" \n",
    "    # TODO: look at this method more closely. So far just copy paste\n",
    "    @staticmethod\n",
    "    def __test(model):\n",
    "        y_pred = model.predict(x_test)\n",
    "        # Converting predictions to label\n",
    "        pred = list()\n",
    "        for i in range(len(y_pred)):\n",
    "            pred.append(np.argmax(y_pred[i]))\n",
    "        # Converting one hot encoded test label to label\n",
    "        test = list()\n",
    "        for i in range(len(y_test)):\n",
    "            test.append(np.argmax(y_test[i]))\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score(pred, test)\n",
    "        # TODO: calculate confusion matrix and put it in result\n",
    "        return accuracy\n",
    "                                    \n",
    "                                    \n",
    "    #--------------- Setter methods for setting parameters --------------------------------------#\n",
    "    \n",
    "    def set_number_of_hidden_layers(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"number_of_hidden_layers\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"number_of_hidden_layers\"] = [val]\n",
    "        \n",
    "    def set_number_of_units_per_hidden_layer(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"number_of_units_per_hidden_layer\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"number_of_units_per_hidden_layer\"] = [val]\n",
    "        \n",
    "    def set_activation_function(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"activation_function\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"activation_function\"] = [val]\n",
    "        \n",
    "    def set_epochs(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"epochs\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"epochs\"] = [val]\n",
    "        \n",
    "    def set_batch_size(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"batch_size\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"batch_size\"] = [val]\n",
    "        \n",
    "    def set_loss_function(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"loss_function\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"loss_function\"] = [val]\n",
    "        \n",
    "    def set_optimizer(self, val):\n",
    "        if isinstance(val, list):\n",
    "            self.parameter_config[\"optimizer\"] = val\n",
    "        else:\n",
    "            self.parameter_config[\"optimizer\"] = [val]\n",
    "        \n",
    "    #--------------- Resets the config to default values --------------------------------------#\n",
    "    \n",
    "    def reset_config(self):\n",
    "        parameter_config = {\n",
    "            'number_of_hidden_layers': [1],\n",
    "            'number_of_units_per_hidden_layer': [10],\n",
    "            'epochs': [100],\n",
    "            'batch_size': [64],\n",
    "            'activation_function': ['relu'],\n",
    "            'loss_function': ['categorical_crossentropy'],\n",
    "            'optimizer': ['sgd']}\n",
    "        \n",
    "        self.parameter_config = parameter_config\n",
    "        \n",
    "        \n",
    "    #--------------- Helper methods -----------------------------------------------------------#\n",
    "        \n",
    "    def __get_number_of_params_with_multiple_vals(self):\n",
    "        number_of_params_with_multiple_vals = 0 \n",
    "        for key in self.parameter_config.keys():\n",
    "            if len(self.parameter_config[key]) > 1:\n",
    "                number_of_params_with_multiple_vals += 1\n",
    "        return number_of_params_with_multiple_vals\n",
    "    \n",
    "    def __get_param_names_with_multiple_vals(self):\n",
    "        param_names_with_multiple_vals = [] \n",
    "        for key in self.parameter_config.keys():\n",
    "            if len(self.parameter_config[key]) > 1:\n",
    "                param_names_with_multiple_vals.append(key)\n",
    "        return param_names_with_multiple_vals\n",
    "        \n",
    "        \n",
    "    #--------------- Plotter methods -----------------------------------------------------------#\n",
    "    \n",
    "    def plot_result(self):\n",
    "        \n",
    "        number_of_params_with_multiple_vals = self.__get_number_of_params_with_multiple_vals()\n",
    "        param_names_with_multiple_vals = self.__get_param_names_with_multiple_vals()\n",
    "        \n",
    "        if number_of_params_with_multiple_vals == 1:\n",
    "            self.__plot_2d(param_names_with_multiple_vals[0])\n",
    "        elif number_of_params_with_multiple_vals == 2:\n",
    "            self.__plot_3d(param_names_with_multiple_vals)\n",
    "        else:\n",
    "            print(\"Plotting for this result is not supported\")\n",
    "            # TODO PCA?\n",
    "        \n",
    "    def __plot_2d(self, param_name_with_multiple_vals):\n",
    "\n",
    "        param_vals = [element['parameter_config'][param_name_with_multiple_vals] for element in self.result]\n",
    "        accuracy_result = [element['result']['accuracy'] for element in self.result]\n",
    "\n",
    "        plt.scatter(param_vals, accuracy_result)\n",
    "        plt.plot(param_vals, accuracy_result, linestyle='--')\n",
    "        plt.title(\"Accuracy per \" + \"'\" + param_name_with_multiple_vals + \"'\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(param_name_with_multiple_vals)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"/n/n\")\n",
    "        \n",
    "        df = pd.DataFrame(list(zip(param_vals, accuracy_result)), \n",
    "               columns =[param_name_with_multiple_vals, 'Accuracy']) \n",
    "        print(df)\n",
    "        \n",
    "        \n",
    "    # TODO sis  \n",
    "    def __plot_3d(self, param_name_with_multiple_vals):\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NN with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nnpt = NeuralNetworkParameterTester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpt.set_number_of_hidden_layers(2)\n",
    "nnpt.set_number_of_units_per_hidden_layer([2, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_hidden_layers': [2],\n",
       " 'number_of_units_per_hidden_layer': [2, 5, 6],\n",
       " 'epochs': [100],\n",
       " 'batch_size': [64],\n",
       " 'activation_function': ['relu'],\n",
       " 'loss_function': ['categorical_crossentropy'],\n",
       " 'optimizer': ['sgd']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.parameter_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 30us/step - loss: 2.3971 - acc: 0.0882\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.3884 - acc: 0.0939\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.3798 - acc: 0.1010\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3668 - acc: 0.1150\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.3458 - acc: 0.1270\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 2.3128 - acc: 0.1423\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.2318 - acc: 0.1693\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.0132 - acc: 0.1815\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.8862 - acc: 0.2056\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.8138 - acc: 0.2280\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.7584 - acc: 0.2656\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.7042 - acc: 0.3108\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.6558 - acc: 0.3376\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.6198 - acc: 0.3523\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5903 - acc: 0.3567\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5660 - acc: 0.3569\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5451 - acc: 0.3538\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5271 - acc: 0.3577\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5116 - acc: 0.3574\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.4977 - acc: 0.3553\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4850 - acc: 0.3565\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4737 - acc: 0.3577\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4637 - acc: 0.3599\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4544 - acc: 0.3596\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4461 - acc: 0.3601\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4381 - acc: 0.3635\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4308 - acc: 0.3625\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4236 - acc: 0.3622\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4161 - acc: 0.3661\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4102 - acc: 0.3696\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4050 - acc: 0.3722\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3999 - acc: 0.3719\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3954 - acc: 0.3720\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3893 - acc: 0.3725\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3852 - acc: 0.3704\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3799 - acc: 0.3757\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3777 - acc: 0.3750\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3715 - acc: 0.3786\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3687 - acc: 0.3726\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3645 - acc: 0.3763\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.3608 - acc: 0.3829\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3559 - acc: 0.3830\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3523 - acc: 0.3838\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3493 - acc: 0.3849\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3473 - acc: 0.3839\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3446 - acc: 0.3844\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3394 - acc: 0.3861\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3383 - acc: 0.3860\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3346 - acc: 0.3870\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3319 - acc: 0.3890\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3294 - acc: 0.3890\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3270 - acc: 0.3895\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3223 - acc: 0.3970\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3211 - acc: 0.3910\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3186 - acc: 0.3933\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3167 - acc: 0.3947\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3138 - acc: 0.3977\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3142 - acc: 0.3951\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3115 - acc: 0.3967\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.3087 - acc: 0.4019\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.3039 - acc: 0.4025\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.3025 - acc: 0.4001\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3019 - acc: 0.4010\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2984 - acc: 0.4049\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3007 - acc: 0.4042\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2940 - acc: 0.4080\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2914 - acc: 0.4057\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2880 - acc: 0.4064\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2852 - acc: 0.4103\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2850 - acc: 0.4093\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2802 - acc: 0.4117\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2775 - acc: 0.4169\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2754 - acc: 0.4139\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2728 - acc: 0.4173\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2701 - acc: 0.4162\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - ETA: 0s - loss: 1.2684 - acc: 0.419 - 0s 15us/step - loss: 1.2676 - acc: 0.4191\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2641 - acc: 0.4183\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2608 - acc: 0.4221\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2582 - acc: 0.4227\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2558 - acc: 0.4205\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2527 - acc: 0.4233\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2501 - acc: 0.4257\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2485 - acc: 0.4257\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2458 - acc: 0.4242\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2440 - acc: 0.4247\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2411 - acc: 0.4242\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2395 - acc: 0.4276\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2389 - acc: 0.4265\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2361 - acc: 0.4271\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2356 - acc: 0.4247\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2335 - acc: 0.4244\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2322 - acc: 0.4232\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2310 - acc: 0.4247\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2296 - acc: 0.4290\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2279 - acc: 0.4255\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2262 - acc: 0.4291\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2263 - acc: 0.4261\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2231 - acc: 0.4301\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2220 - acc: 0.4294\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2207 - acc: 0.4304\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 31us/step - loss: 2.4016 - acc: 0.0874\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.3990 - acc: 0.0900\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.3978 - acc: 0.0949\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.3957 - acc: 0.1010\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.3902 - acc: 0.1101\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.3698 - acc: 0.1256\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.2731 - acc: 0.1433\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.1029 - acc: 0.1871\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.9527 - acc: 0.2032\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.8392 - acc: 0.2354\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.7591 - acc: 0.2670\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.6826 - acc: 0.3173\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.6093 - acc: 0.3812\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.5406 - acc: 0.4188\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.4765 - acc: 0.4404\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.4196 - acc: 0.4547\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3665 - acc: 0.4704\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.3212 - acc: 0.4824\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2812 - acc: 0.4942\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.2473 - acc: 0.5008\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.2155 - acc: 0.5123\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1866 - acc: 0.5201\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1589 - acc: 0.5377\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.1295 - acc: 0.5530\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.0998 - acc: 0.5660\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.0674 - acc: 0.5794\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 1.0337 - acc: 0.5878\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.9960 - acc: 0.5931\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.9585 - acc: 0.5983\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.9218 - acc: 0.6052\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8921 - acc: 0.6093\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8669 - acc: 0.6209\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8458 - acc: 0.6223: 0s - loss: 0.8537 - acc: \n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8284 - acc: 0.6368\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.8122 - acc: 0.6458\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7981 - acc: 0.6553\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7846 - acc: 0.6643\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7730 - acc: 0.6706\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7608 - acc: 0.6736\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7494 - acc: 0.6849\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7382 - acc: 0.6900\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7263 - acc: 0.6935\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.7115 - acc: 0.7022\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6974 - acc: 0.7112\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6823 - acc: 0.7145\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6668 - acc: 0.7228\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6506 - acc: 0.7276\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6343 - acc: 0.7309\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6180 - acc: 0.7351\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.6004 - acc: 0.7399\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5842 - acc: 0.7477\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5679 - acc: 0.7524\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5538 - acc: 0.7598\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5390 - acc: 0.7695\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.5154 - acc: 0.7875\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4891 - acc: 0.8119\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4695 - acc: 0.8225\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4492 - acc: 0.8305\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4354 - acc: 0.8365\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4247 - acc: 0.8386\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4128 - acc: 0.8441\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4044 - acc: 0.8479\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3961 - acc: 0.8512\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3883 - acc: 0.8537\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3817 - acc: 0.8561\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3757 - acc: 0.8580\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3698 - acc: 0.8621\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3649 - acc: 0.8638\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3605 - acc: 0.8648\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3557 - acc: 0.8660\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3506 - acc: 0.8699\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3467 - acc: 0.8701\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3435 - acc: 0.8704\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3402 - acc: 0.8722\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3364 - acc: 0.8731\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3324 - acc: 0.8721\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3304 - acc: 0.8747\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3281 - acc: 0.8748\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3252 - acc: 0.8762\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3275 - acc: 0.8744\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3198 - acc: 0.8785\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3168 - acc: 0.8798\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3152 - acc: 0.8803\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3127 - acc: 0.8811\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3100 - acc: 0.8807\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3071 - acc: 0.8820\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3060 - acc: 0.8818\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3057 - acc: 0.8824\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3029 - acc: 0.8832\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3005 - acc: 0.8837\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2988 - acc: 0.8847\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2971 - acc: 0.8852\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2967 - acc: 0.8847\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2949 - acc: 0.8865\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2929 - acc: 0.8860\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2916 - acc: 0.8861\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2903 - acc: 0.8878\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2891 - acc: 0.8881\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2874 - acc: 0.8884\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2861 - acc: 0.8889\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 32us/step - loss: 2.3928 - acc: 0.1062\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.2939 - acc: 0.1532\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 2.0297 - acc: 0.2538\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.7194 - acc: 0.3325\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.4641 - acc: 0.4145\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.2706 - acc: 0.4871\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 1.1044 - acc: 0.5756\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.9465 - acc: 0.6473\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.8238 - acc: 0.6944\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.7314 - acc: 0.7286\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.6540 - acc: 0.7619\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.5792 - acc: 0.7887\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.4986 - acc: 0.8267\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.4252 - acc: 0.8600\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3697 - acc: 0.8835\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.3322 - acc: 0.8944\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.3083 - acc: 0.9006\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2935 - acc: 0.9019\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2819 - acc: 0.9059\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2732 - acc: 0.9078\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2650 - acc: 0.9106\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2598 - acc: 0.9112\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2566 - acc: 0.9118\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2528 - acc: 0.9129\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2485 - acc: 0.9142\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2457 - acc: 0.9147\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2431 - acc: 0.9169\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2412 - acc: 0.9155\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2394 - acc: 0.9168\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2380 - acc: 0.9183\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2359 - acc: 0.9183\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2331 - acc: 0.9208\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2313 - acc: 0.9193\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2298 - acc: 0.9197\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2283 - acc: 0.9209\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2280 - acc: 0.9197\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2257 - acc: 0.9203\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2245 - acc: 0.9199\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2230 - acc: 0.9227\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2228 - acc: 0.9221\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2203 - acc: 0.9238\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2192 - acc: 0.9230\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2180 - acc: 0.9244\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2170 - acc: 0.9251\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2164 - acc: 0.9239\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2166 - acc: 0.9233\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2159 - acc: 0.9242\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2142 - acc: 0.9240\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2135 - acc: 0.9258\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2121 - acc: 0.9253\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2097 - acc: 0.9268\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2107 - acc: 0.9271\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2088 - acc: 0.9286\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2077 - acc: 0.9275\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2084 - acc: 0.9264\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2079 - acc: 0.9290\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2080 - acc: 0.9281\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2069 - acc: 0.9278\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2053 - acc: 0.9272\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2035 - acc: 0.9293\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.2032 - acc: 0.9296\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2024 - acc: 0.9308\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2021 - acc: 0.9295\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2015 - acc: 0.9303\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2004 - acc: 0.9306\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.2005 - acc: 0.9316\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1987 - acc: 0.9319\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1979 - acc: 0.9313\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1974 - acc: 0.9319\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1960 - acc: 0.9330\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1963 - acc: 0.9337\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1942 - acc: 0.9328\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1929 - acc: 0.9349\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1940 - acc: 0.9343\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1916 - acc: 0.9343\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1906 - acc: 0.9357\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1910 - acc: 0.9356\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1884 - acc: 0.9360\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1881 - acc: 0.9369\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1871 - acc: 0.9371\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1857 - acc: 0.9370\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1859 - acc: 0.9368\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1838 - acc: 0.9363\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1823 - acc: 0.9392\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1826 - acc: 0.9384\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1814 - acc: 0.9405\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1818 - acc: 0.9404\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1808 - acc: 0.9401\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 15us/step - loss: 0.1802 - acc: 0.9406\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1781 - acc: 0.9412\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1778 - acc: 0.9414\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1770 - acc: 0.9418\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1762 - acc: 0.9420\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1751 - acc: 0.9437\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1753 - acc: 0.9432\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1730 - acc: 0.9436\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1732 - acc: 0.9423\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1728 - acc: 0.9427\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1712 - acc: 0.9433\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 14us/step - loss: 0.1716 - acc: 0.9435\n"
     ]
    }
   ],
   "source": [
    "nnpt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parameter_config': {'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_hidden_layer': 2,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x20a7e40c108>,\n",
       "   'accuracy': 0.4159261790840738}},\n",
       " {'parameter_config': {'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_hidden_layer': 5,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x20a7f8ed848>,\n",
       "   'accuracy': 0.8872180451127819}},\n",
       " {'parameter_config': {'number_of_hidden_layers': 2,\n",
       "   'number_of_units_per_hidden_layer': 6,\n",
       "   'epochs': 100,\n",
       "   'batch_size': 64,\n",
       "   'activation_function': 'relu',\n",
       "   'loss_function': 'categorical_crossentropy',\n",
       "   'optimizer': 'sgd'},\n",
       "  'result': {'model': <keras.engine.sequential.Sequential at 0x20a7facd788>,\n",
       "   'accuracy': 0.9323308270676691}}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpt.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number_of_units_per_hidden_layer  Accuracy\n",
      "0                                 2  0.415926\n",
      "1                                 5  0.887218\n",
      "2                                 6  0.932331\n"
     ]
    }
   ],
   "source": [
    "nnpt.plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot Matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
