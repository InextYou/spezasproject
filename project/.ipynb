{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"../data/Component_Faults_Data.csv\"\n",
    "df = pd.read_csv(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, :48].values\n",
    "y = df[\"class\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper class for building, training, testing NN, and plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "\n",
    "    # params for building model\n",
    "    input_layer_dim = 48\n",
    "    output_layer_dim = 11\n",
    "\n",
    "    def build(self, number_of_hidden_layers=1, number_of_units_per_layer=48,\n",
    "              activation_function='relu', loss_function='categorical_crossentropy', optimizer='sgd'):\n",
    "\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import Dense\n",
    "\n",
    "        model = Sequential()\n",
    "        # Input layer\n",
    "        model.add(Dense(number_of_units_per_layer, input_dim=self.input_layer_dim, activation=activation_function))\n",
    "        # Hidden layer\n",
    "        for i in range(number_of_hidden_layers):\n",
    "            model.add(Dense(number_of_units_per_layer, activation=activation_function))\n",
    "        # Output layer\n",
    "        model.add(Dense(self.output_layer_dim, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def train(model, epochs=100, batch_size=64):\n",
    "        # xtrain and ytrain are from preprocessing\n",
    "        history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "        return model, history\n",
    "    \n",
    "    @staticmethod\n",
    "    def test(model):\n",
    "        y_pred = model.predict(x_test)\n",
    "        # Converting predictions to label\n",
    "        pred = list()\n",
    "        for i in range(len(y_pred)):\n",
    "            pred.append(np.argmax(y_pred[i]))\n",
    "        # Converting one hot encoded test label to label\n",
    "        test = list()\n",
    "        for i in range(len(y_test)):\n",
    "            test.append(np.argmax(y_test[i]))\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score(pred, test)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nn = NN()\n",
    "#res_acc_per_param = {}\n",
    "#\n",
    "#for j in range(4, 6):\n",
    "#    model = nn.build(number_of_hidden_layers=j, number_of_units_per_layer=48)\n",
    "#    trained_model, history = nn.train(model, x_train, y_train, batch_size=64, epochs=100)\n",
    "#    accuracy = nn.test(trained_model)\n",
    "#    \n",
    "#    res_acc_per_param.update({j: accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newer Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkParameterTester:\n",
    "\n",
    "    # params for building model\n",
    "    input_layer_dim = 48\n",
    "    output_layer_dim = 11\n",
    "    \n",
    "    param_list = {}    \n",
    "    acc_per_param = {}\n",
    "    \n",
    "    def __init__(self, param_name, param_val_list,\n",
    "                 activation_function='relu', loss_function='categorical_crossentropy', optimizer='sgd'):\n",
    "        acc_per_param = {}\n",
    "\n",
    "        for val in param_val_list:\n",
    "            # For Build\n",
    "            if param_name == \"number_of_hidden_layers\":\n",
    "                model = self.build(activation_function, loss_function, optimizer, number_of_hidden_layers=val)\n",
    "            elif param_name == \"number_of_units_per_layer\":\n",
    "                model = self.build(activation_function, loss_function, optimizer, number_of_units_per_layer=val)\n",
    "            elif param_name == \"activation_function\":\n",
    "                model = self.build(activation_function, loss_function, optimizer, activation_function=val)\n",
    "            elif param_name == \"loss_function\":\n",
    "                model = self.build(activation_function, loss_function, optimizer, loss_function=val)\n",
    "            elif param_name == \"optimizer\":\n",
    "                model = self.build(activation_function, loss_function, optimizer, optimizer=val)\n",
    "            else:\n",
    "                model = self.build()\n",
    "                \n",
    "            # For train\n",
    "            if param_name == \"epochs\":\n",
    "                trained_model, history = self.train(model, epochs=val)\n",
    "            elif param_name == \"batch_size\":\n",
    "                trained_model, history = self.train(model, batch_size=val)\n",
    "            else:\n",
    "                trained_model, history = self.train(model)\n",
    "            \n",
    "            accuracy = self.test(trained_model)\n",
    "\n",
    "            acc_per_param.update({val: accuracy})\n",
    "            \n",
    "        self.acc_per_param = acc_per_param\n",
    "\n",
    "\n",
    "    def build(self, activation_function, loss_function, optimizer,\n",
    "              number_of_hidden_layers=1, number_of_units_per_layer=48):\n",
    "        \n",
    "        self.param_list.update({\"number_of_hidden_layers\": number_of_hidden_layers, \n",
    "                               \"number_of_units_per_layer\": number_of_units_per_layer,\n",
    "                               \"activation_function\": activation_function,\n",
    "                               \"loss_function\": loss_function,\n",
    "                               \"optimizer\": optimizer})\n",
    "\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import Dense\n",
    "\n",
    "        model = Sequential()\n",
    "        # Input layer\n",
    "        model.add(Dense(number_of_units_per_layer, input_dim=self.input_layer_dim, activation=activation_function))\n",
    "        # Hidden layer\n",
    "        for i in range(number_of_hidden_layers):\n",
    "            model.add(Dense(number_of_units_per_layer, activation=activation_function))\n",
    "        # Output layer\n",
    "        model.add(Dense(self.output_layer_dim, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, model, epochs=100, batch_size=64):\n",
    "        self.param_list.update({\"epochs\": epochs, \"batch_size\": batch_size})\n",
    "        # xtrain and ytrain are from preprocessing\n",
    "        history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "        return model, history\n",
    "    \n",
    "    @staticmethod\n",
    "    def test(model):\n",
    "        y_pred = model.predict(x_test)\n",
    "        # Converting predictions to label\n",
    "        pred = list()\n",
    "        for i in range(len(y_pred)):\n",
    "            pred.append(np.argmax(y_pred[i]))\n",
    "        # Converting one hot encoded test label to label\n",
    "        test = list()\n",
    "        for i in range(len(y_test)):\n",
    "            test.append(np.argmax(y_test[i]))\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score(pred, test)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "\n",
    "    def plot(self, result, variable_param_name, dim=2):\n",
    "        if dim == 2:\n",
    "            self.plot_2d(result, variable_param_name)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_2d(result, variable_param_name):\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.plot(list(result.keys()), list(result.values()))\n",
    "        plt.title(\"Acurracy per \" + \"'\" + variable_param_name + \"'\")\n",
    "        plt.ylabel(\"Acurracy\")\n",
    "        plt.xlabel(variable_param_name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NN with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 43us/step - loss: 2.4069 - acc: 0.0935\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.3993 - acc: 0.0834\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.3970 - acc: 0.0921\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 2.3947 - acc: 0.1068\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.3914 - acc: 0.1134\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.3823 - acc: 0.1172\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.3226 - acc: 0.1294\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.1093 - acc: 0.1848\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.9726 - acc: 0.1956\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.8893 - acc: 0.2183\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.8344 - acc: 0.2578\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.7934 - acc: 0.2844\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.7603 - acc: 0.3094\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.7328 - acc: 0.3252\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.7095 - acc: 0.3357\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.6893 - acc: 0.3415: 0s - loss: 1.6929 - acc\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.6712 - acc: 0.3477\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.6548 - acc: 0.3502\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.6396 - acc: 0.3530\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.6249 - acc: 0.3554\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.6102 - acc: 0.3612\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.5936 - acc: 0.3683\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.5698 - acc: 0.3764\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.5384 - acc: 0.3813\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.5143 - acc: 0.3851\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4964 - acc: 0.3852\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4816 - acc: 0.3858\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.4686 - acc: 0.3852\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4575 - acc: 0.3854\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4474 - acc: 0.3859\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.4380 - acc: 0.3847\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4297 - acc: 0.3877\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4220 - acc: 0.3866\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.4147 - acc: 0.3901\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.4083 - acc: 0.3852\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4019 - acc: 0.3887\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.3963 - acc: 0.3876\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3905 - acc: 0.3901\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3848 - acc: 0.3929\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3804 - acc: 0.3898\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3759 - acc: 0.3891\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3715 - acc: 0.3894\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.3669 - acc: 0.3920\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 1s 20us/step - loss: 1.3630 - acc: 0.3878\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3593 - acc: 0.3914\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3552 - acc: 0.3950\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3517 - acc: 0.3896\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3481 - acc: 0.3958\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3450 - acc: 0.3925\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3416 - acc: 0.3920\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3383 - acc: 0.3955\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3355 - acc: 0.3959\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3324 - acc: 0.3974\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.3298 - acc: 0.3965\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3269 - acc: 0.4006\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3245 - acc: 0.3988\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3215 - acc: 0.4027\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.3190 - acc: 0.4021\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3163 - acc: 0.4025\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3144 - acc: 0.4019\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.3114 - acc: 0.4043\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3090 - acc: 0.4046\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3064 - acc: 0.4081\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3043 - acc: 0.4087\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3018 - acc: 0.4050\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2991 - acc: 0.4127\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2969 - acc: 0.4148\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2950 - acc: 0.4128\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2928 - acc: 0.4152\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2906 - acc: 0.4132\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2886 - acc: 0.4135\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.2870 - acc: 0.4123\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2854 - acc: 0.4151\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2837 - acc: 0.4149\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2815 - acc: 0.4148\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2804 - acc: 0.4172\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2785 - acc: 0.4159\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2766 - acc: 0.4170\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2753 - acc: 0.4134\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2736 - acc: 0.4145\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2719 - acc: 0.4161\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2704 - acc: 0.4154\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2690 - acc: 0.4172\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2678 - acc: 0.4147\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2662 - acc: 0.4183\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2648 - acc: 0.4187\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2632 - acc: 0.4149\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2622 - acc: 0.4163\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2610 - acc: 0.4164\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2589 - acc: 0.4179\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2582 - acc: 0.4173\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2564 - acc: 0.4193\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2555 - acc: 0.4197\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2547 - acc: 0.4189\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2527 - acc: 0.4198\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2528 - acc: 0.4184\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2516 - acc: 0.4185\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2502 - acc: 0.4171\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2497 - acc: 0.4195\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2477 - acc: 0.4197: 0s - loss: 1.2436 - acc: \n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 42us/step - loss: 2.2455 - acc: 0.1951\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.9148 - acc: 0.2112\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.6919 - acc: 0.2252\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.5333 - acc: 0.3139\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4241 - acc: 0.3910\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3476 - acc: 0.4544\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2875 - acc: 0.4892\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.2377 - acc: 0.5171\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.1951 - acc: 0.5368\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.1584 - acc: 0.5507\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.1260 - acc: 0.5620\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.0974 - acc: 0.5710\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.0709 - acc: 0.5794\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.0470 - acc: 0.5871\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.0253 - acc: 0.5900\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.0051 - acc: 0.5968\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.9863 - acc: 0.6005\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.9692 - acc: 0.5940\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.9529 - acc: 0.6051\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.9379 - acc: 0.6042\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.9237 - acc: 0.6097\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.9107 - acc: 0.6079\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.8985 - acc: 0.6168\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.8869 - acc: 0.6158\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.8765 - acc: 0.6156\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.8666 - acc: 0.6172\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.8571 - acc: 0.6203\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.8487 - acc: 0.6224\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.8405 - acc: 0.6219\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.8327 - acc: 0.6205\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.8253 - acc: 0.6246\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.8185 - acc: 0.6244\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.8119 - acc: 0.6260\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.8081 - acc: 0.6238\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.8017 - acc: 0.6298\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7960 - acc: 0.6335\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.7910 - acc: 0.6289\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7859 - acc: 0.6391\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7816 - acc: 0.6358\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7768 - acc: 0.6303\n",
      "Epoch 41/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7732 - acc: 0.6432\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7696 - acc: 0.6300\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7658 - acc: 0.6434\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7626 - acc: 0.6446\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7595 - acc: 0.6445\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7563 - acc: 0.6417\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7534 - acc: 0.6432\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7509 - acc: 0.6439\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7478 - acc: 0.6471\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7473 - acc: 0.6441\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.7434 - acc: 0.6435\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7414 - acc: 0.6447\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7386 - acc: 0.6464\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7367 - acc: 0.6465\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7343 - acc: 0.6470\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7329 - acc: 0.6441\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7305 - acc: 0.6467\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7287 - acc: 0.6475\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7268 - acc: 0.6510\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7253 - acc: 0.6488\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7235 - acc: 0.6494\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7221 - acc: 0.6485\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7202 - acc: 0.6497\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7187 - acc: 0.6462\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7164 - acc: 0.6521\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7157 - acc: 0.6469\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7139 - acc: 0.6516\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7130 - acc: 0.6533\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7116 - acc: 0.6597\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7109 - acc: 0.6603\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7085 - acc: 0.6710\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7073 - acc: 0.6766\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7061 - acc: 0.6808\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7033 - acc: 0.6797\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7025 - acc: 0.6784\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7002 - acc: 0.6833\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.6987 - acc: 0.6800\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.6965 - acc: 0.6849\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6948 - acc: 0.6845\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6924 - acc: 0.6832\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6901 - acc: 0.6862\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6882 - acc: 0.6870\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6853 - acc: 0.6871\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6832 - acc: 0.6876\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6810 - acc: 0.6891\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6782 - acc: 0.6873\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6760 - acc: 0.6852\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6732 - acc: 0.6872\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.6710 - acc: 0.6849\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6684 - acc: 0.6877\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.6683 - acc: 0.6871\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6651 - acc: 0.6872\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6625 - acc: 0.6852\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6600 - acc: 0.6880\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6581 - acc: 0.6859\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.6559 - acc: 0.6860\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6537 - acc: 0.6867\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6514 - acc: 0.6893\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6505 - acc: 0.6865\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6482 - acc: 0.6898\n",
      "Epoch 1/100\n",
      "26329/26329 [==============================] - 1s 42us/step - loss: 2.3999 - acc: 0.0972\n",
      "Epoch 2/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.3919 - acc: 0.1015\n",
      "Epoch 3/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.3781 - acc: 0.1149\n",
      "Epoch 4/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.2941 - acc: 0.1587\n",
      "Epoch 5/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.1843 - acc: 0.1650\n",
      "Epoch 6/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.1427 - acc: 0.1782\n",
      "Epoch 7/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.1102 - acc: 0.1878\n",
      "Epoch 8/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 2.0672 - acc: 0.1990\n",
      "Epoch 9/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 2.0103 - acc: 0.2335\n",
      "Epoch 10/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.9540 - acc: 0.2621\n",
      "Epoch 11/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.9029 - acc: 0.2702\n",
      "Epoch 12/100\n",
      "26329/26329 [==============================] - 1s 20us/step - loss: 1.8439 - acc: 0.2927\n",
      "Epoch 13/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.7732 - acc: 0.3192\n",
      "Epoch 14/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.7210 - acc: 0.3440\n",
      "Epoch 15/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.6706 - acc: 0.3767\n",
      "Epoch 16/100\n",
      "26329/26329 [==============================] - 1s 20us/step - loss: 1.6204 - acc: 0.3957\n",
      "Epoch 17/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 1.5740 - acc: 0.4135\n",
      "Epoch 18/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 1.5317 - acc: 0.4159\n",
      "Epoch 19/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.4911 - acc: 0.4216\n",
      "Epoch 20/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.4529 - acc: 0.4343\n",
      "Epoch 21/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.4184 - acc: 0.4334\n",
      "Epoch 22/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3874 - acc: 0.4429\n",
      "Epoch 23/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3621 - acc: 0.4437\n",
      "Epoch 24/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.3389 - acc: 0.4557\n",
      "Epoch 25/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 1.3154 - acc: 0.4639\n",
      "Epoch 26/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2905 - acc: 0.4827\n",
      "Epoch 27/100\n",
      "26329/26329 [==============================] - 1s 19us/step - loss: 1.2604 - acc: 0.4831\n",
      "Epoch 28/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.2096 - acc: 0.4718\n",
      "Epoch 29/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 1.1270 - acc: 0.5081\n",
      "Epoch 30/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 1.0439 - acc: 0.5729\n",
      "Epoch 31/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.9814 - acc: 0.5954\n",
      "Epoch 32/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.9361 - acc: 0.6099\n",
      "Epoch 33/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.9005 - acc: 0.6218\n",
      "Epoch 34/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.8711 - acc: 0.6326\n",
      "Epoch 35/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.8474 - acc: 0.6404\n",
      "Epoch 36/100\n",
      "26329/26329 [==============================] - 1s 19us/step - loss: 0.8262 - acc: 0.6529\n",
      "Epoch 37/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.8074 - acc: 0.6572\n",
      "Epoch 38/100\n",
      "26329/26329 [==============================] - 1s 23us/step - loss: 0.7915 - acc: 0.6641\n",
      "Epoch 39/100\n",
      "26329/26329 [==============================] - 1s 27us/step - loss: 0.7760 - acc: 0.6717\n",
      "Epoch 40/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.7609 - acc: 0.6776\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26329/26329 [==============================] - 1s 19us/step - loss: 0.7471 - acc: 0.6847\n",
      "Epoch 42/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.7344 - acc: 0.6881\n",
      "Epoch 43/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7216 - acc: 0.6970\n",
      "Epoch 44/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.7083 - acc: 0.7021\n",
      "Epoch 45/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6949 - acc: 0.7130\n",
      "Epoch 46/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6809 - acc: 0.7214\n",
      "Epoch 47/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.6670 - acc: 0.7287\n",
      "Epoch 48/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.6521 - acc: 0.7412\n",
      "Epoch 49/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6365 - acc: 0.7524\n",
      "Epoch 50/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.6199 - acc: 0.7639\n",
      "Epoch 51/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.6046 - acc: 0.7673\n",
      "Epoch 52/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.5882 - acc: 0.7767\n",
      "Epoch 53/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.5722 - acc: 0.7856\n",
      "Epoch 54/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.5551 - acc: 0.7902\n",
      "Epoch 55/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.5351 - acc: 0.8029\n",
      "Epoch 56/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.5120 - acc: 0.8167\n",
      "Epoch 57/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4931 - acc: 0.8283\n",
      "Epoch 58/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.4788 - acc: 0.8330\n",
      "Epoch 59/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.4677 - acc: 0.8392\n",
      "Epoch 60/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.4579 - acc: 0.8444\n",
      "Epoch 61/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4492 - acc: 0.8476\n",
      "Epoch 62/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4418 - acc: 0.8483\n",
      "Epoch 63/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4344 - acc: 0.8514\n",
      "Epoch 64/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4280 - acc: 0.8542\n",
      "Epoch 65/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.4214 - acc: 0.8534\n",
      "Epoch 66/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.4153 - acc: 0.8559\n",
      "Epoch 67/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.4095 - acc: 0.8568\n",
      "Epoch 68/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.4048 - acc: 0.8599\n",
      "Epoch 69/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.4010 - acc: 0.8598\n",
      "Epoch 70/100\n",
      "26329/26329 [==============================] - 1s 21us/step - loss: 0.3977 - acc: 0.8621\n",
      "Epoch 71/100\n",
      "26329/26329 [==============================] - 1s 19us/step - loss: 0.3948 - acc: 0.8602\n",
      "Epoch 72/100\n",
      "26329/26329 [==============================] - 1s 19us/step - loss: 0.3931 - acc: 0.8612\n",
      "Epoch 73/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3906 - acc: 0.8621\n",
      "Epoch 74/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3888 - acc: 0.8623\n",
      "Epoch 75/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3865 - acc: 0.8635\n",
      "Epoch 76/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3847 - acc: 0.8648\n",
      "Epoch 77/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.3820 - acc: 0.8658\n",
      "Epoch 78/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3815 - acc: 0.8648\n",
      "Epoch 79/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.3793 - acc: 0.8665\n",
      "Epoch 80/100\n",
      "26329/26329 [==============================] - 1s 20us/step - loss: 0.3784 - acc: 0.8663\n",
      "Epoch 81/100\n",
      "26329/26329 [==============================] - 1s 20us/step - loss: 0.3765 - acc: 0.8661\n",
      "Epoch 82/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3753 - acc: 0.8665\n",
      "Epoch 83/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3736 - acc: 0.8690\n",
      "Epoch 84/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3730 - acc: 0.8680\n",
      "Epoch 85/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3711 - acc: 0.8674\n",
      "Epoch 86/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3702 - acc: 0.8686\n",
      "Epoch 87/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3683 - acc: 0.8679\n",
      "Epoch 88/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3675 - acc: 0.8684\n",
      "Epoch 89/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3660 - acc: 0.8679\n",
      "Epoch 90/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3658 - acc: 0.8690\n",
      "Epoch 91/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3640 - acc: 0.8697\n",
      "Epoch 92/100\n",
      "26329/26329 [==============================] - 0s 16us/step - loss: 0.3633 - acc: 0.8702\n",
      "Epoch 93/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3629 - acc: 0.8699\n",
      "Epoch 94/100\n",
      "26329/26329 [==============================] - 0s 19us/step - loss: 0.3612 - acc: 0.8695\n",
      "Epoch 95/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3605 - acc: 0.8717\n",
      "Epoch 96/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3596 - acc: 0.8709\n",
      "Epoch 97/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3583 - acc: 0.8710\n",
      "Epoch 98/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3579 - acc: 0.8717\n",
      "Epoch 99/100\n",
      "26329/26329 [==============================] - 0s 17us/step - loss: 0.3566 - acc: 0.8731\n",
      "Epoch 100/100\n",
      "26329/26329 [==============================] - 0s 18us/step - loss: 0.3561 - acc: 0.8727\n"
     ]
    }
   ],
   "source": [
    "nnpt = NeuralNetworkParameterTester(\"number_of_units_per_layer\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEXCAYAAACgUUN5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5wU9f3H8deHo/feOQEBEZF6gtgigjUqxgqWSKKxixKT/JKYqNHEGKNiQ7HEig0Lxi6oKIiiFBEB5Tj60eHocMDdfX5/zJxZzit7cLt7d/t+Ph77uCnfnfnM3Ox+dr6z+xlzd0REJHlVSXQAIiKSWEoEIiJJTolARCTJKRGIiCQ5JQIRkSSnRCAikuSUCESiYGbDzezzchDHL8xshZltN7PexbRbamaDi5h3rJktKOa5z5jZ34uZ72bWqXSRR6+k9UvZUyJIADP71Mw2mVmNRMdS0YRvEsMTHUcC3QNc5+513f2b/VmAu09x90PKOK5KLUys7RMdR6woEcRZeDAdCzhwZozWUTWaaeVdRYw5Gge4XQcB88oqFglU1mMtWkoE8fdLYBrwDHBp5Awzq2Vm95rZMjPbYmafh9OON7PMAm1/PPU3s9vM7DUzG2tmW4HhRUzrZ2ZfmtlmM1ttZg+bWfWIZR5mZhPNLMvM1prZn82spZntNLMmEe36mtl6M6tWcOMi1vuKmW0zs1lm1jNifmszez18/hIzG1HIc3+Mubgdmd9dY2b3hGdYS8zs1ML2UcTyx4bD7cMujl+FXS2bzOwqMzvCzOaE++jhn67SHgr/Nz+Y2aCIGQ3M7D/hfl1pZn83s5SIOKea2SgzywJuK2abqpjZX8JjYJ2ZPRcuu4aZbQdSgG/NbFFx+ybUK9yWLeH/o2a4jn2OJzPrHf6ftpnZK0DNAjH9PtyuVWb26wLzaoT7f3l4zIwxs1qR6zGzm8JtWW1mv4oi7sjlNzKzd8LjZVM43Dacd56ZzSzQ/iYze7MUsf2fma0BnjazpuHyN4evgSlmlhTvkUmxkeXML4EXwsfJZtYiYt49QF/gKKAx8AcgL8rlDgFeAxqGyy5sWi4wEmgKDAAGAdcAmFk94CPgA6A10An42N3XAJ8C50es62LgZXffW0wsr4bb8CLwpplVC19UbwPfAm3C9d9oZieXsB0/cvfh7v5MxKT+wIJwm+4G/mNmVkRchekPdAYuAO4HbgYGA4cB55vZzwq0XRyu61bgDTNrHM57Fsgh2G+9gZOAywt5bnPgH8XEMzx8DAQ6AnWBh919t7vXDdv0dPeDo9i284FTgA5ADwpJrBZ8EHgTeJ7g//UqcE7E/FOA3wEnEuyngtcd/gV0AXoRbHsb4JaI+S2BBuH0y4DRZtYoitjzVQGeJjgTSgV2AfkJ+i2gg5kdGtH+4nBboo2tcbjsK4CbgEygGdAC+DPBmTvu3t7dl5Yi7orF3fWI0wM4BtgLNA3HfwBGhsNVCA7ynoU873ggs8C0pcDgcPg2YHKB+T+ZVshybwTGh8PDgG+KaHcBMDUcTgHWAP2KaHsbMC1ivAqwmqA7rD+wvED7PwFPRxtzgecOBzIixmsTvHBbFtxHEcsfGw63D9u2iZi/EbggYvx14MaIda0CLGL+18AlBG8au4FaEfOGAZMinrs8ym36GLgmYvyQ8JipGo470CmK5SwFLo4YvxsYU/B4Ao4rZLu+AP4eDj8F3BUxr0t+DIABO4CDI+YPAJZErGdXfuzhtHXAkSXE/kz++guZ1wvYFDH+KPCPcPgwYBNQI8rY9gA1I+bfDvw3mv1b2R5J3S+WAJcCE9x9Qzj+YjhtFMGnzJpANKf8hVlR0jQz6wLcB6QRvGlWBfJPrdsVs+7/AmPMrCPBG8EWd/86mljcPS/shmhN8AbS2sw2R7RNAaaUsB3FWROxrp3hyUDdopv/xNqI4V2FjEcua6WH7xihZQTbdRBQDVgdcTJShX23Jdrtah0uN3IdVQmSzcool5FvTcTwznDZha2vsO2KnD+ziHnNCI6jmRHbbQT/03wb3T2nQBxR/3/MrDbB6+MUIP9Mop6Zpbh7LsGZ2Etm9heCpDzO3XebWfMoYlvv7tkR4/8m+LAwIXzO4+5+V7SxVmRKBHES9k2eD6SEfZIQfHJpaEEf+ndANnAwQddJpB0EB3X+slIIXoSRCisjW3Dao8A3wDB332ZmNwLnhvNWEHyK/elC3LPNbBxwEdCV/516F6VdRKxVgLYEnzpzCD6RdS7muWVZDnef/UbQFXAg2piZRbxpphJ0T6wgOCNoWuBNL1K027WKILHkSyXYb2sLb37AVlP4di2KmN8uon1qxPAGgmR5mLuXNklF6yaCs6L+7r7GzHoRHMMG4O7TzGwPwRnnheEj2tj2+Z+4+7ZwfTeZ2WHAJDOb7u4fl/VGlTe6RhA/ZxH00XcjOL3tBRxK8Gn4l+6eR3Aafp8FF1RTzGyABV8xTQdqmtnPLbhA+xeCJFJa9YCtwHYz6wpcHTHvHaClmd0YXmSrZ2b9I+Y/R9DFcSYwtoT19DWzsy34JsaNBG+S0wi6UraGF+hqhdvY3cyO2I9ticZsYGh4fSKN/yW9/dUcGBEu7zyC/9977r4amADca2b1wwu+Bxe4vhCtl4CRZtbBzOoCdwKvFJNgDtSXBIlmhJlVNbOzgX4R88cRfNGgW/jp/Nb8GeEx+wQwKvwEjpm1KXDN50DVI3hD3xxej7m1kDbPEVw3yHH3z/c3NjM73cw6hdeYthK8XnPLcFvKLSWC+LmUoC98ubuvyX8QHMAXhW+avyM4M5gOZBFc7Kri7lsILuo+SdA9sIPgolZp/Y7gE9M2ghfJK/kzwk9DJwJnEHQpLCS4YJk/fyrBhetZXvJFs/8SXFfYRHC6fra77w1P5c8gSIJLCD61PUlwMTEW/kpwhrUJ+BtBV9yB+IrggukGggu+57r7xnDeL4HqwPxwfa8BrfZjHU8RnHFNJthH2cD1BxZ20dx9D3A2QZLfRPB/eyNi/vsEF9E/ATLCv5H+L5w+zYJven1E8Am+rNwP1CLY59MIvsxQ0PNAd356plra2DqHbbYTJMhH3P3TAwm+orB9uwZFimZmnwAvuvuTxbS5jeBi28VxC0ySWtjtug7o4+4LEx1PRaRrBBKVsPumD8HXO0XKk6uB6UoC+09dQ1IiM3uW4JT5xrALSQ5A+MOm7YU8xpRiGalFLGO7maWWvITEMrN5RcR+USmXsxS4geAir+wndQ2JiCQ5nRGIiCS5CneNoGnTpt6+fftEhyEiUqHMnDlzg7sX/P0RUAETQfv27ZkxY0aiwxARqVDMbFlR89Q1JCKS5JQIRESSnBKBiEiSUyIQEUlySgQiIklOiUBEJMkpEYiIJDklAhGRci57by7PTF3Cmi3ZJTfeDxXuB2UiIsliT04er8xYwehPMlizNZucPOfyYzuW+XqUCEREypm9uXm8PjOThz7JYOXmXaQd1Ij7LujJUQc3jcn6lAhERMqJnNw83py9igc/XsjyrJ30bNeQf559OMd2bkpwB83YUCIQEUmw3DznnTmreOCjhSzesIPuberz1PA0Bh7SPKYJIJ8SgYhIguTlOe/PXcP9H6WzcN12urasx2OX9OWkbi3ikgDyKRGIiMSZuzNh/lpGTUznhzXb6NS8LqMv7MOp3VtSpUr8EkA+JQIRkThxdyYtWMd9E9OZu3IrHZrW4YGhvTi9R2tSEpAA8ikRiIjEmLszZeEG7puYzuwVm0ltXJt7zuvJWb1aUzUl8T/nUiIQEYmhLzKCBDBj2SbaNKzFXWcfzjl921KtHCSAfEoEIiIxMH1pFvdOWMC0xVm0rF+TO87qzgVp7ahetfwkgHxKBCIiZWjW8k2MmpjOlIUbaFavBree0Y1h/VKpWS0l0aEVSYlARKQMzMnczKiJ6UxasJ4mdapz82mHcvGRB1GrevlNAPmUCEREDsC8VVu4/6OFTJy/loa1q/GHUw7h0gHtqVOj4ry9VpxIRUTKkfS12xg1MZ33566hfs2q3HRiF4Yf3Z56NaslOrRSUyIQESmFReu3c/9HC3lnzirqVK/KiEGdueyYDjSoVfESQD4lAhGRKCzdsIMHP1nIm9+spGa1FK7+2cH85tiONKpTPdGhHTAlAhGRYqzI2slDnyzk9VkrqZZiXH5sR644riNN69ZIdGhlRolARKQQqzbv4uFJGYybvoIqVYxfDjiIq48/mOb1aiY6tDKnRCAiEmHt1mwemZTBS1+vwHGG9UvlmoEH06pBrUSHFjNKBCIiwPptuxnz2SLGTltGbp5zXlpbrh3YibaNaic6tJhTIhCRpJa1Yw+PTV7Ec18sY3dOLmf3acuIEzqT2qTyJ4B8SgQikpQ279zDk1OW8PTUJezcm8uQnq0ZMagzHZvVTXRocadEICJJZWv2Xp76fAn/mbKEbbtz+HmPVtw4qDOdW9RLdGgJo0QgIklh++4cnv1iKY9PXsyWXXs5+bAWjDyxC11b1k90aAmnRCAildrOPTk8/+UyHpu8mKwdexjUtTkjT+xC9zYNEh1auaFEICKVUvbeXF74ajmPfprBhu17+FmXZow8sQu92jVMdGjljhKBiFQqu3NyeWX6CkZPymDt1t0c3akJYwZ3Ia1940SHVm7FNBGY2SnAA0AK8KS731VgfirwLNAwbPNHd38vljGJSOW0JyeP12Zm8vAnC1m1JZt+7RvzwNDeHNmxSaJDK/dilgjMLAUYDZwIZALTzewtd58f0ewvwDh3f9TMugHvAe1jFZOIVD45uXm8MWslD36ykMxNu+id2pC7z+3J0Z2aYGaJDq9CiOUZQT8gw90XA5jZy8AQIDIROJB/yb4BsCqG8YhIJZKb5/x39koe/HghSzfupEfbBtxxVneO79JMCaCUYpkI2gArIsYzgf4F2twGTDCz64E6wODCFmRmVwBXAKSmppZ5oCJSceTlOe98t5oHPkpn0fodHNqqPk/8Mo3BhzZXAthPsUwEhf1HvMD4MOAZd7/XzAYAz5tZd3fP2+dJ7o8DjwOkpaUVXIaIJIG8POfDeWsY9VE66Wu3c0iLeoy5uA8ndWtJlSpKAAcilokgE2gXMd6Wn3b9XAacAuDuX5pZTaApsC6GcYlIBeLufPT9OkZNTGf+6q0c3KwODw3rzc8Pb6UEUEZimQimA53NrAOwEhgKXFigzXJgEPCMmR0K1ATWxzAmEakg3J1P09czamI6czK30L5JbUZd0JMze7YhRQmgTMUsEbh7jpldB3xI8NXQp9x9npndDsxw97eAm4AnzGwkQbfRcHdX149IEnN3pmZs5L6JC5i1fDNtG9Xi7nN7cHbvNlRNqZLo8CqlmP6OIPxNwHsFpt0SMTwfODqWMYhIxTFt8Ubum5jO10uyaN2gJnf+4nDO7duW6lWVAGJJvywWkYSbuSyL+yamMzVjI83r1eD2IYdxwRHtqFE1JdGhJQUlAhFJmNkrNnPfxHQmp6+nad3q/PX0blzUP5Wa1ZQA4kmJQETibu7KLYyamM7HP6yjUe1q/OnUrlwy4CBqV9dbUiJor4tI3Hy/eiv3f5TOh/PW0qBWNX5/8iFcelR76tbQW1Eiae+LSMwtXLuN+z9eyLtzVlOvRlVuHNyZXx/Tgfo1qyU6NEGJQERiaPH67Tz48UL+++0qaldL4bqBnfjNsR1pUFsJoDxRIhCRMrd8404e/GQhb8zKpEbVFK44riNXHncwjetUT3RoUgglAhEpM5mbdjJ6UgavzsgkpYrxq6M7cNXPDqZZvRqJDk2KoUQgIgdszZZsRk/K4OXpyzGMi/qncs3ATrSoXzPRoUkUlAhEZL+t25bNI5MW8eLXy3F3zk9rx7UDO9G6Ya1EhyaloEQgIqW2cftuHpu8mOe+XMreXOfcPm257oROtGtcO9GhyX5QIhCRqG3asYcnpizmmS+Wkr03l7N6t2HECZ1p37ROokOTA6BEICIl2rJrL/+Zspinpi5lx54czujRmhGDOtOped1EhyZlQIlARIq0LXsvT09dyhNTFrMtO4fTDm/JDYO6cEjLeokOTcqQEoGI/MSO3Tk8++VSHp+8mM0793JitxbcOLgzh7VukOjQJAaUCETkR7v25DJ22jLGfLaIjTv2MPCQZow8sQs92jZMdGgSQ0oEIkL23lxe+no5j3y6iPXbdnNs56aMPLELfVIbJTo0iQMlApEktjsnl3EzMhn9SQZrtmZzZMfGjL6wD/06NE50aBJHSgQiSWhvbh6vz8zkoU8yWLl5F2kHNeK+C3py1MFNEx2aJIASgUgSycnN483Zq3jw44Usz9pJz3YN+efZh3Ns56aYWaLDkwRRIhBJArl5zjtzVvHARwtZvGEH3dvU56nhaQw8pLkSgCgRiFRmeXnO+3PXcP9H6Sxct52uLevx2CV9OalbCyUA+ZESgUgl5O5MmL+WURPT+WHNNjo1r8voC/twaveWVKmiBCD7UiIQqUTcnUkL1nHfxHTmrtxKh6Z1eGBoL07v0ZoUJQApghKBSCXg7kxeuIH7Jqbz7YrNpDauzT3n9eSsXq2pmlIl0eFJOadEIFLBfZERJIAZyzbRpmEt7jr7cM7p25ZqSgASJSUCkQrq6yVZ3DdxAdMWZ9Gyfk3uOKs7F6S1o3pVJQApHSUCkQpm1vJNjJqYzpSFG2hWrwa3ntGNYf1SqVktJdGhSQWlRCBSQczJ3MyoielMWrCeJnWqc/Nph3LxkQdRq7oSgBwYJQKRcm7eqi3c/9FCJs5fS8Pa1fjDKYdw6YD21Kmhl6+UDR1JIuVU+tptjJqYzvtz11C/ZlVuOrELw49uT72a1RIdmlQySgQi5UzGuu088PFC3pmzijrVqzJiUGcuO6YDDWopAUhsKBGIlBNLN+zgwY8X8ubsldSslsLVPzuY3xzbkUZ1qic6NKnkYpoIzOwU4AEgBXjS3e8qMH8UMDAcrQ00d3fdCkmSyoqsnTz0yUJen7WSainG5cd25IrjOtK0bo1EhyZJImaJwMxSgNHAiUAmMN3M3nL3+flt3H1kRPvrgd6xikekvFm1eRcPT8pg3PQVVKli/HLAQVx9/ME0r1cz0aFJkonlGUE/IMPdFwOY2cvAEGB+Ee2HAbfGMB6RcmHt1mwemZTBS1+vwHGG9Uvl2oGdaNlACUASI5aJoA2wImI8E+hfWEMzOwjoAHwSw3hEEmr9tt2M+WwRY6ctIzfPOS+tLded0Jk2DWslOjRJcrFMBIWVOvQi2g4FXnP33EIXZHYFcAVAampq2UQnEidZO/bw2ORFPPfFMnbn5HJ2n7aMOKEzqU1qJzo0ESC2iSATaBcx3hZYVUTbocC1RS3I3R8HHgdIS0srKpmIlCubd+7hySlLeHrqEnbuzWVIz9aMGNSZjs3qJjo0kX3EMhFMBzqbWQdgJcGb/YUFG5nZIUAj4MsYxiISN1uz9/LU50v4z5QlbNudw897tGLk4M50al4v0aGJFCpmicDdc8zsOuBDgq+PPuXu88zsdmCGu78VNh0GvOzu+qQvFdr23Tk8+8VSHp+8mC279nLyYS0YeWIXurasn+jQRIoV098RuPt7wHsFpt1SYPy2WMYgEg8T56/l/16fQ9aOPQw+tDk3Du5C9zYNEh2WSFT0y2KRA5Cb59z/UToPfZLB4W0a8NTwI+jVTr+JlIqlxERgZo3dPSsewYhUJJt37uGGl2fzWfp6zuvbljvO6q57AkiFFM0ZwVdmNht4GnhfffkiMH/VVq4aO5PVW3bxj19058J+qZjp5vBSMUVzT7suBF/dvATIMLM7zaxLbMMSKb/e/GYlZz86ld05ubxy5QAu6n+QkoBUaCWeEYRnABOBiWY2EBgLXGNm3wJ/dHd97VOSwt7cPO5873uenrqUfh0aM/rCPjSrp8JwUvFFc42gCXAxwRnBWuB64C2gF/AqQWkIkUpt3bZsrnvhG75emsWvj+7An07rSrUU3SReKodorhF8CTwPnOXumRHTZ5jZmNiEJVJ+zFy2iWtemMmWXXt5YGgvhvRqk+iQRMpUNIngkKIuELv7v8o4HpFyw9154avl/O3tebRqUIvx1/Tj0Fb6cZhUPtGc204wsx+/GG1mjczswxjGJJJw2Xtz+cNrc/jLm3M5ulNT3r7uGCUBqbSiOSNo5u6b80fcfZOZNY9hTCIJlblpJ1ePncV3K7cwYlBnbhzUmSpV9K0gqbyiSQS5Zpbq7svhx3sH6LcEUil9vnAD1780i5xc58lfpjG4W4tEhyQSc9EkgpuBz83ss3D8OMJ7A4hUFu7OY5MXc/cHP9CpeV3GXNxX5aIlaUTzO4IPzKwPcCTBzWZGuvuGmEcmEifbd+fwh9e+5b3v1vDzHq24+5we1KmhMlySPKI92nOBdUBNoJuZ4e6TYxeWSHwsWr+dK5+fyeL12/nzaV35zbEd9SthSTrR/KDscuAGgjuMzSY4M/gSOCG2oYnE1oR5a7hp3LdUq1qFsZf156hOTRMdkkhCRPP10RuAI4Bl7j4Q6A2sj2lUIjGUm+fcO2EBVzw/kw7N6vD29ccoCUhSi6ZrKNvds80MM6vh7j+Et5cUqXAiS0efn9aW24eodLRINIkgM/xB2ZsEhec2UfRN6EXKrfmrtnLl2Bms2ZLNnb84nGH92ul6gAjRfWvoF+HgbWY2CWgAfBDTqETK2PhvMvnTG9/RsFZ1XrlyAH1SGyU6JJFyo9hEYGZVgDnu3h3A3T8rrr1IebM3N49/vPs9z3yh0tEiRSk2Ebh7npl9G/nLYpGKIrJ09GXHdOCPp6p0tEhhorlG0AqYZ2ZfAzvyJ7r7mTGLSuQAqXS0SPSiSQR/i3kUImXE3Rn71XJuV+lokaiVdI0gBfiruw+OUzwi+y17by5/eXMur83MZOAhzbj/gt40qF0t0WGJlHslXSPINbOdZtbA3bfEKyiR0srctJOrxs5k7sqt3DCoMzeodLRI1KL6QRnwnZlNZN9rBCNiFpVIKah0tMiBiSYRvBs+RMqVgqWjH7skjQ5N6yQ6LJEKJ5oflD0bj0BESmP77hx+/+q3vD9XpaNFDlQ01UeXUMgdydy9Y0wiEilBZOnom087lMuP7aBSESIHIJqPUGkRwzWB84DGsQlHpHgfhqWjq6t0tEiZiaZraGOBSfeb2efALbEJSeSncvOcURPTeXhSBj3bNuDRi/vSumGtRIclUilE0zXUJ2K0CsEZQr2YRSRSwOadexjx8mwmp6/ngrR2/G3IYSodLVKGoukaujdiOAdYApwfm3BE9jVv1RauGjuTtVt288+zD2dYv9REhyRS6UTTNTQwHoGIFDT+m0z++Pp3NKpdnVeuPJLeKh0tEhMllmI0szvDG9Pkjzcys79Hs3AzO8XMFphZhpn9sYg255vZfDObZ2YvRh+6VFZ7c/O47a15jHzlW3q1a8jb1x+jJCASQ9HU5D3V3Tfnj7j7JuC0kp4U1ikaDZwKdAOGmVm3Am06A38Cjnb3w4AbSxG7VELrtmVz4RPTeOaLpVx+TAfGXt5f9w8QibForhGkhPcq3g1gZrWAaF6Z/YAMd18cPu9lYAgwP6LNb4DRYXLB3deVJnipXGYuy+LqsbPYlp3Dg8N6c2bP1okOSSQpRJMIxgIfm9nT4fivgGh+bdwGWBExngn0L9CmC4CZTQVSgNvc/Se3wTSzK4ArAFJTdbGwsnF3xk5bxu3vzKd1w1o8+2uVjhaJp2guFt9tZnOAwYAR3K/4oCiWXdhPPQv+Qrkq0Bk4HmgLTDGz7pFdUWEMjwOPA6Slpf3kV85Scal0tEjiRVucZQ2QR/C10SXA61E8JxNoFzHeFlhVSJtp7r4XWGJmCwgSw/Qo45IKbEXWTq5+QaWjRRKtyERgZl2AocAwYCPwCmCl+DrpdKCzmXUAVobLurBAmzfD5T9jZk0JuooWl2oLpEKasnA9I176hpw85z+XpjHoUJWOFkmU4s4IfgCmAGe4ewaAmY2MdsHunmNm1wEfEvT/P+Xu88zsdmCGu78VzjvJzOYDucDvCylpIZWIuzPms8X8+8Mf6Ny8HmMu6avS0SIJVlwiOIfgU/wkM/sAeJnC+/2L5O7vAe8VmHZLxLADvw0fUslFlo4+vUcr/qXS0SLlQpGvQncfD4w3szrAWcBIoIWZPQqMd/cJcYpRKoGMddu58vkZLN24k7/8/FAuO0alo0XKixJ/UObuO9z9BXc/neCC72yg0F8JixTmw3lrOGv0VDbv3Mvzl/Xj8mM7KgmIlCOlOi939yzgsfAhUqzcPOe+iQsYPWmRSkeLlGPqoJWY2LRjDyNe/oYpCzcw9Ih23HamSkeLlFdKBFLm5q4MSkev26rS0SIVgRKBlKk3ZmXypze+o3Gd6oy7agC92jUs+UkiklBKBFIm9uTk8Y935/Psl8vo36Exoy/qQ9O6qhoqUhEoEcgBW7c1m2tfnMX0pZu4/JgO/PHUrlRNiabCuYiUB0oEckBUOlqk4lMikP3i7jw/bRm3vz2fNo1q8dxl/ejaUqWjRSoiJQIptey9udw8fi6vz8rkhK7NGXVBLxrUUulokYpKiUBKZUXWTq4aO5N5q7Zy4+DOjDhBpaNFKjolAonalIXruf6lb8hV6WiRSkWJQErk7jz62SLu+XABnZvX47FL+tJepaNFKg0lAinWtuy9/P7VOXwwbw1n9GzNv845nNrVddiIVCZ6RUuRVDpaJDkoEUihPpi7ht+9+i01qlZh7GX9GXBwk0SHJCIxokQg+8jNc+6dsIBHPl1Ez3YNGXNxH1o1UOlokcpMiUB+FFk6eli/oHR0jaoqHS1S2SkRCLBv6ei7zj6coSodLZI0lAiE12dm8ufxKh0tkqyUCJLYnpw8/v7ufJ77chlHdmzMwxeqdLRIMlIiSFLrtmZzzQuzmLFsE785tgP/d4pKR4skKyWCJDRjaRZXvzCL7dk5PDSsN2eodLRIUlMiSCKRpaPbNqrF2Mv6c0jLeokOS0QSTIkgSWTvzeXP47/jjVkrGdS1OfepdLSIhJQIkkB+6ej5q7cycnAXrj+hk0pHi8iPlAgqucnp6xnx8v9KR5/QVaWjRWRfSgSVlLvzyKeLuGfCAg5pUY8xF6t0tIgUTomgEibfKzsAABBXSURBVNqWvZffvfotH85bq9LRIlIivTtUMhnrtnHF8zNZptLRIhIlJYJK5IO5a7hp3GxqVU9R6WgRiZoSQSWQm+fcM2EBj366iF7tGvKoSkeLSCkoEVRwkaWjL+yfyq1ndFPpaBEplZgWlzGzU8xsgZllmNkfC5k/3MzWm9ns8HF5LOOpbOau3MLpD33OV4uz+Nc5h3PnLw5XEhCRUovZGYGZpQCjgROBTGC6mb3l7vMLNH3F3a+LVRyV1WszM7k5LB396lUD6KnS0SKyn2LZNdQPyHD3xQBm9jIwBCiYCKQUIktHD+jYhIcu7K3S0SJyQGKZCNoAKyLGM4H+hbQ7x8yOA9KBke6+omADM7sCuAIgNTV575y1NiwdPXPZJq44riN/OPkQlY4WkQMWy3eRwr687gXG3wbau3sP4CPg2cIW5O6Pu3uau6c1a9asjMOsGKYvzeL0hz7n+9VbefjC3vz5tEOVBESkTMTynSQTaBcx3hZYFdnA3Te6++5w9AmgbwzjqZDcnWe/WMqwx6dRt0ZVxl9zNKf30P0DRKTsxLJraDrQ2cw6ACuBocCFkQ3MrJW7rw5HzwS+j2E8Fc6uPbncPP473vhmJYMPbc6956t0tIiUvZglAnfPMbPrgA+BFOApd59nZrcDM9z9LWCEmZ0J5ABZwPBYxVPRrMjayZXPz+T7NVv57YlduG6gSkeLSGyYe8Fu+/ItLS3NZ8yYkegwYuqz9PWMeOkb3J0HhvZmYNfmiQ5JRCo4M5vp7mmFzdMvi8uRgqWjH7ukLwc1UeloEYktJYJyYlv2Xm4a9y0T5q/lzJ6tuUulo0UkTvROUw5Elo7+6+nd+PXR7VU6WkTiRokgwT6Yu5qbxn1LreopvHB5f47sqNLRIhJfSgQJotLRIlJeKBEkQNaOPYx46Rs+z1DpaBFJPCWCOJu7cgtXPj+T9dt3c/c5PTj/iHYlP0lEJIaUCOIov3R0kzrVefVKlY4WkfJBiSAO9uTkccc783l+2jKOOrgJDw3rTROVjhaRckKJIMbWbs3m6rEzmbV8M1ce15Hfq3S0iJQzSgQx9PWSLK59cRY7ducw+sI+/LxHq0SHJCLyE0oEMZBfOvrv735Pu8a1eeHy/nRpUS/RYYmIFEqJoIztWzq6Bfdd0JP6NVU6WkTKLyWCMrR8406uHDuTH9Zs5aYTu3CtSkeLSAWgRFBGPl2wjhteno2789TwIxh4iEpHi0jFoERwgPLynEc/U+loEam4lAgOQGTp6CG9WvPPs1U6WkQqHr1r7aeFa7dx5fMzWZa1k1tO78avVDpaRCooJYL98P53q/ndq0Hp6Bcv709/lY4WkQpMiaAUcnLzuGdCOmM+W0Tv1IY8elFfWjaomeiwREQOiBJBlCJLR1/UP5VbVDpaRCoJJYIofJe5havGqnS0iFROSgQleHXGCm5+cy5N61TntasG0KOtSkeLSOWiRFCEPTl53P7OPMZOW87RnZrw4FCVjhaRykmJoBD7lI7+WUd+f5JKR4tI5aVEUMDXS7K45oVZ7Nyj0tEikhyUCELuzjNfLOUf735PauPavPgblY4WkeSgREBQOvrP479jvEpHi0gSSvpEoNLRIpLskjoR5JeOBlQ6WkSSVlImgrw855FPM7h3YjpdW9bnsYv7ktqkdqLDEhFJiKRLBFvD0tETw9LRd53dg1rVVSpCRJJXUiWC/NLRy7N2cusZ3Rh+lEpHi4jE9FdSZnaKmS0wswwz+2Mx7c41MzeztFjF8uG8NQwZPZWt2Tm8cHl/fnV0ByUBERFieEZgZinAaOBEIBOYbmZvufv8Au3qASOAr2IVC0D1lCoc2qo+oy/so9LRIiIRYtk11A/IcPfFAGb2MjAEmF+g3R3A3cDvYhgLA7s252ddmumroSIiBcSya6gNsCJiPDOc9iMz6w20c/d3YhjHj5QERER+KpaJoLB3Xf9xplkVYBRwU4kLMrvCzGaY2Yz169eXYYgiIhLLRJAJRN7BpS2wKmK8HtAd+NTMlgJHAm8VdsHY3R939zR3T2vWrFkMQxYRST6xTATTgc5m1sHMqgNDgbfyZ7r7Fndv6u7t3b09MA04091nxDAmEREpIGaJwN1zgOuAD4HvgXHuPs/MbjezM2O1XhERKZ2Y/qDM3d8D3isw7ZYi2h4fy1hERKRwuu2WiEiSUyIQEUly5u4ltypHzGw9sGw/n94U2FCG4ZQVxVU6iqv0ymtsiqt0DiSug9y90K9dVrhEcCDMbIa7x6ye0f5SXKWjuEqvvMamuEonVnGpa0hEJMkpEYiIJLlkSwSPJzqAIiiu0lFcpVdeY1NcpROTuJLqGoGIiPxUsp0RiIhIAUoEIiJJrlIkAjN7yszWmdncIuabmT0Y3jJzjpn1iZh3qZktDB+Xxjmui8J45pjZF2bWM2LeUjP7zsxmm1mZFuKLIq7jzWxLuO7ZZnZLxLyobj8ao7h+HxHTXDPLNbPG4bxY7q92ZjbJzL43s3lmdkMhbeJ+jEUZV9yPsSjjivsxFmVccT/GzKymmX1tZt+Gcf2tkDY1zOyVcJ98ZWbtI+b9KZy+wMxO3q8g3L3CP4DjgD7A3CLmnwa8T3CPhCOBr8LpjYHF4d9G4XCjOMZ1VP76gFPz4wrHlwJNE7S/jgfeKWR6CrAI6AhUB74FusUrrgJtzwA+idP+agX0CYfrAekFtzsRx1iUccX9GIsyrrgfY9HElYhjLDxm6obD1Qhu23tkgTbXAGPC4aHAK+Fwt3Af1QA6hPsupbQxVIozAnefDGQV02QI8JwHpgENzawVcDIw0d2z3H0TMBE4JV5xufsX4XohKMPdtqzWfSBxFePH24+6+x4g//ajiYhrGPBSWa27OO6+2t1nhcPbCKrptinQLO7HWDRxJeIYi3J/FSVmx9h+xBWXYyw8ZraHo9XCR8Fv8QwBng2HXwMGmZmF0192993uvgTIINiHpVIpEkEUirptZom304yjywg+UeZzYIKZzTSzKxIQz4DwVPV9MzssnFYu9peZ1SZ4M309YnJc9ld4St6b4FNbpIQeY8XEFSnux1gJcSXsGCtpf8X7GDOzFDObDawj+OBQ5PHlQYn/LUATymh/xbQMdTlS1G0zi72dZryY2UCCF+kxEZOPdvdVZtYcmGhmP4SfmONhFkFdku1mdhrwJtCZcrK/CE7Zp7p75NlDzPeXmdUleGO40d23FpxdyFPicoyVEFd+m7gfYyXElbBjLJr9RZyPMXfPBXqZWUNgvJl1d/fIa2UxPb6S5YygqNtmlnQ7zZgzsx7Ak8AQd9+YP93dV4V/1wHj2Y/Tvf3l7lvzT1U9uKdENTNrSjnYX6GhFDhlj/X+MrNqBG8eL7j7G4U0ScgxFkVcCTnGSoorUcdYNPsrFPdjLFz2ZuBTftp9+ON+MbOqQAOCbtSy2V9lfeEjUQ+gPUVf/Pw5+17I+zqc3hhYQnARr1E43DiOcaUS9OkdVWB6HaBexPAXwClxjKsl//uxYT9gebjvqhJc7OzA/y7kHRavuML5+S+AOvHaX+G2PwfcX0ybuB9jUcYV92MsyrjifoxFE1cijjGgGdAwHK4FTAFOL9DmWva9WDwuHD6MfS8WL2Y/LhZXiq4hM3uJ4FsITc0sE7iV4IIL7j6G4C5ppxG8IHYCvwrnZZnZHQT3Vwa43fc9FYx1XLcQ9PM9Elz3IceDyoItCE4PIXhhvOjuH8QxrnOBq80sB9gFDPXgqMsxs/zbj6YAT7n7vDjGBfALYIK774h4akz3F3A0cAnwXdiPC/BngjfZRB5j0cSViGMsmrgScYxFExfE/xhrBTxrZikEvTTj3P0dM7sdmOHubwH/AZ43swyCJDU0jHmemY0D5gM5wLUedDOVikpMiIgkuWS5RiAiIkVQIhARSXJKBCIiSU6JQEQkySkRiIgkOSUCEZEkp0QgFYKZfWpmaXFc37/DksD/LmL+M2Z2biHTW5vZa0U8p9BtMLPhZvbwgUe9zzK3l9xKJFApflAmUhwzq+pBoa7SuBJo5u67S/MkD8oQ/CRBVCZh1Utz97xExyJlQ2cEUqbMrH14448nwk/UE8ysVuSnYTNramZLw+HhZvammb1tZkvM7Doz+62ZfWNm0yy8KUjoYgturjLXzPqFz69jwQ1tpofPGRKx3FfN7G1gQhGxWvjJf64FNxy5IJz+FkEZga/ypxXhuDCexflnB+H2zw2Ha5nZyxbcFOYVgvIB+ev+lZmlm9lnBL94zZ/ezMxeD7dnupkdHU6/LdzOT8P1jYjy/1HXzD42s1nhNubvnzss4sYsZvaP/GVacHOW6WHcf4vYru/N7BGCgnHtwrOi/H03Mpp4pJwqi1oZeuiR/yCoFZQD9ArHxwEXExTSSgunNQWWhsPDCcoy1COoubIFuCqcN4qgQiTh858Ih48jrEcE3AlcHA43JLjZSJ1wuZkUU9cHOIfg/gApBCUElgOtwnnbS9jOZ4BXCT5MdSOooZ+//fmx/ZagRAJAj3C/pBGUFFgebm91YCrwcNjuReCYcDgV+D4cvo2gvk2NcP9tBKoVE9/28G9VoH7Efs8gqLnTHpgVTq9CcEOTJsBJwONhmyrAO+H+bg/kEd4wBehLUC45f30NE33s6bH/D3UNSSwscff8Wi4zCd5EijPJgxuFbDOzLcDb4fTvCN5A870EwQ1szKy+BSV7TwLONLPfhW1qEtaOIbwhTDHrPQZ4yYPaLGvDT+dHAG+VuIWBNz3oHplvZi0KmX8c8GAY8xwzmxNO7w986u7rAcKzhS7hvMFAt7CmDUB9M6sXDr/rQVfVbjNbR5C8MkuI0YA7zew4gjfyNkALd19qZhvNrHe4nG/cfaOZnUSwT78Jn1+XoDz0cmCZBzfdgaC4WUczewh4lyLOuqRiUCKQWIjsV88l6BLJ4X9dkTWLaZ8XMZ7HvsdowcJY+fXYz3H3BZEzzKw/sIPiFVbLvTQi4y5qWUUV8ypqehVggLvvipwYJoaC+zWa1+9FBGcefd19b9gll7//nyQ4c2oJPJW/KuCf7v5YgfW3J2J/uvsmC+5/fDJBZczzgV9HEY+UQ7pGIPGylKA7Afb/Ymp+H/4xwBZ330JQpfL68AIm4SfcaE0GLrDg7lDNCD7Bf72fsRW1/IvCuLrzv7Obr4DjzayJBfXxz4t4zgTguvwRM+t1gDE0ANaFSWAgcFDEvPEEde+PINiPhH9/bcHNWzCzNhbciGUfFtw7oIq7vw78leBe01JB6YxA4uUeYJyZXQJ8sp/L2GRmXwD1+d+nzzuA+4E5YTJYCpwe5fLGAwMI6rk78Ad3X7OfsRXmUeDpsEtoNmGScffVZnYb8CWwmuDia0r4nBHA6PA5VQmSyVUHEMMLwNtmNiOM4Yf8Ge6+x8wmAZvD7jHcfYKZHQp8GebW7QTXeAqWNm4Tblv+h8k/HUCMkmAqQy2SpMI38VnAee6+MNHxSOKoa0gkCZlZN4JvEH2sJCA6I5BKz8wOB54vMHm3u/eP4rk3s28fPsCr7v6Psopvf5lZE+DjQmYN8oh7E4uURIlARCTJqWtIRCTJKRGIiCQ5JQIRkSSnRCAikuT+H1XohrnARz+VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "\n",
      "number_of_units_per_layer :\t 3\n",
      "activation_function :\t\t relu\n",
      "loss_function :\t\t categorical_crossentropy\n",
      "optimizer :\t\t sgd\n",
      "epochs :\t\t 100\n",
      "batch_size :\t\t 64\n"
     ]
    }
   ],
   "source": [
    "Plotter().plot(nnpt.acc_per_param, \"number_of_hidden_layers\")\n",
    "print(\"\\nParameters:\\n\")\n",
    "for index, key in enumerate(nnpt.param_list.keys()):\n",
    "    if key != \"number_of_hidden_layers\":\n",
    "        if index == 1:\n",
    "            print(key, \":\\t\", nnpt.param_list[key])\n",
    "        if index != 1:\n",
    "            print(key, \":\\t\\t\", nnpt.param_list[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
